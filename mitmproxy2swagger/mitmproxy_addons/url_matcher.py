#!/usr/bin/env python3
"""
URLåŒ¹é…æ¨¡å—
å®ç°URLç›¸ä¼¼åº¦åŒ¹é…ç®—æ³•ï¼Œæ”¯æŒå¤šç§åŒ¹é…ç­–ç•¥
"""

import re
from typing import Dict, List, Tuple, Optional
from urllib.parse import urlparse, parse_qs
from difflib import SequenceMatcher


class URLMatcher:
    """URLåŒ¹é…å™¨ï¼Œæ”¯æŒå¤šç§åŒ¹é…ç­–ç•¥"""

    def __init__(self):
        self.similarity_threshold = 0.6  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆè°ƒæ•´åé€‚åˆæ–°çš„æƒé‡åˆ†é…ï¼‰
        self.base_url_weight = 0.6      # åŸºç¡€URLæƒé‡
        self.params_weight = 0.4        # å‚æ•°æƒé‡

    def calculate_string_similarity(self, str1: str, str2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦
        ä½¿ç”¨SequenceMatcherç®—æ³•ï¼ˆåŸºäºRatcliff/Obershelpç®—æ³•ï¼‰

        Args:
            str1: å­—ç¬¦ä¸²1
            str2: å­—ç¬¦ä¸²2

        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (0.0 - 1.0)
        """
        if not str1 or not str2:
            return 0.0

        # æ ‡å‡†åŒ–å­—ç¬¦ä¸²ï¼ˆè½¬å°å†™ï¼Œå»é™¤å¤šä½™ç©ºæ ¼ï¼‰
        str1_norm = str1.lower().strip()
        str2_norm = str2.lower().strip()

        if str1_norm == str2_norm:
            return 1.0

        # ä½¿ç”¨SequenceMatcherè®¡ç®—ç›¸ä¼¼åº¦
        matcher = SequenceMatcher(None, str1_norm, str2_norm)
        return matcher.ratio()

    def calculate_jaccard_similarity(self, str1: str, str2: str) -> float:
        """
        è®¡ç®—Jaccardç›¸ä¼¼åº¦ï¼ˆåŸºäºå­—ç¬¦é›†åˆï¼‰

        Args:
            str1: å­—ç¬¦ä¸²1
            str2: å­—ç¬¦ä¸²2

        Returns:
            Jaccardç›¸ä¼¼åº¦åˆ†æ•° (0.0 - 1.0)
        """
        if not str1 or not str2:
            return 0.0

        set1 = set(str1.lower())
        set2 = set(str2.lower())

        intersection = len(set1.intersection(set2))
        union = len(set1.union(set2))

        return intersection / union if union > 0 else 0.0

    def calculate_levenshtein_similarity(self, str1: str, str2: str) -> float:
        """
        è®¡ç®—åŸºäºç¼–è¾‘è·ç¦»çš„ç›¸ä¼¼åº¦

        Args:
            str1: å­—ç¬¦ä¸²1
            str2: å­—ç¬¦ä¸²2

        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (0.0 - 1.0)
        """
        if not str1 or not str2:
            return 0.0

        if str1 == str2:
            return 1.0

        # è®¡ç®—ç¼–è¾‘è·ç¦»
        len1, len2 = len(str1), len(str2)
        dp = [[0] * (len2 + 1) for _ in range(len1 + 1)]

        for i in range(len1 + 1):
            dp[i][0] = i
        for j in range(len2 + 1):
            dp[0][j] = j

        for i in range(1, len1 + 1):
            for j in range(1, len2 + 1):
                if str1[i-1] == str2[j-1]:
                    dp[i][j] = dp[i-1][j-1]
                else:
                    dp[i][j] = min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1

        max_len = max(len1, len2)
        return 1.0 - (dp[len1][len2] / max_len) if max_len > 0 else 0.0

    def extract_base_url(self, url: str) -> str:
        """
        æå–URLä¸­é—®å·å‰çš„éƒ¨åˆ†ï¼ˆåŸºç¡€URLï¼‰

        Args:
            url: å®Œæ•´URL

        Returns:
            åŸºç¡€URLï¼ˆé—®å·å‰çš„éƒ¨åˆ†ï¼‰
        """
        if '?' in url:
            return url.split('?')[0]
        return url

    def parse_url_components(self, url: str) -> Dict[str, any]:
        """
        è§£æURLç»„ä»¶

        Args:
            url: å®Œæ•´URL

        Returns:
            URLç»„ä»¶å­—å…¸
        """
        parsed = urlparse(url)

        return {
            'scheme': parsed.scheme,
            'netloc': parsed.netloc,
            'path': parsed.path,
            'params': parsed.params,
            'query': parsed.query,
            'fragment': parsed.fragment,
            'base_url': f"{parsed.scheme}://{parsed.netloc}{parsed.path}",
            'query_params': parse_qs(parsed.query) if parsed.query else {}
        }

    def match_base_url_exact(self, url1: str, url2: str) -> bool:
        """
        æ£€æŸ¥ä¸¤ä¸ªURLçš„åŸºç¡€éƒ¨åˆ†ï¼ˆé—®å·å‰ï¼‰æ˜¯å¦å®Œå…¨åŒ¹é…

        Args:
            url1: URL 1
            url2: URL 2

        Returns:
            æ˜¯å¦å®Œå…¨åŒ¹é…
        """
        base1 = self.extract_base_url(url1)
        base2 = self.extract_base_url(url2)
        return base1 == base2

    def calculate_url_similarity(self, url1: str, url2: str) -> Dict[str, float]:
        """
        è®¡ç®—ä¸¤ä¸ªURLçš„ç»¼åˆç›¸ä¼¼åº¦

        Args:
            url1: URL 1
            url2: URL 2

        Returns:
            ç›¸ä¼¼åº¦ç»“æœå­—å…¸
        """
        # è§£æURLç»„ä»¶
        comp1 = self.parse_url_components(url1)
        comp2 = self.parse_url_components(url2)

        # 1. åŸºç¡€URLç›¸ä¼¼åº¦ï¼ˆå¤šç§ç®—æ³•ï¼‰
        base_similarity_seq = self.calculate_string_similarity(comp1['base_url'], comp2['base_url'])
        base_similarity_jaccard = self.calculate_jaccard_similarity(comp1['base_url'], comp2['base_url'])
        base_similarity_levenshtein = self.calculate_levenshtein_similarity(comp1['base_url'], comp2['base_url'])

        # åŸºç¡€URLç»¼åˆç›¸ä¼¼åº¦ï¼ˆå–å¹³å‡å€¼ï¼‰
        base_similarity = (base_similarity_seq + base_similarity_jaccard + base_similarity_levenshtein) / 3

        # 2. æŸ¥è¯¢å‚æ•°ç›¸ä¼¼åº¦
        query_similarity = self.calculate_string_similarity(comp1['query'], comp2['query'])

        # 3. å®Œæ•´URLç›¸ä¼¼åº¦
        full_similarity_seq = self.calculate_string_similarity(url1, url2)
        full_similarity_jaccard = self.calculate_jaccard_similarity(url1, url2)
        full_similarity_levenshtein = self.calculate_levenshtein_similarity(url1, url2)

        full_similarity = (full_similarity_seq + full_similarity_jaccard + full_similarity_levenshtein) / 3

        # 4. åŸºç¡€URLå®Œå…¨åŒ¹é…æ£€æŸ¥
        base_exact_match = self.match_base_url_exact(url1, url2)

        # 5. ç»¼åˆè¯„åˆ† - ğŸ¯ ä¿®å¤ï¼šé™ä½åŸºç¡€URLæƒé‡ï¼Œæé«˜æŸ¥è¯¢å‚æ•°æƒé‡
        if base_exact_match:
            # å¦‚æœåŸºç¡€URLå®Œå…¨åŒ¹é…ï¼Œä»éœ€è¦é‡è§†æŸ¥è¯¢å‚æ•°çš„ç›¸ä¼¼åº¦
            # å¯¹äºAPI URLï¼ŒæŸ¥è¯¢å‚æ•°å¾€å¾€æ¯”åŸºç¡€URLæ›´é‡è¦
            composite_score = 0.3 + (query_similarity * 0.7)
        else:
            # å¦åˆ™ä½¿ç”¨åŠ æƒå¹³å‡
            composite_score = (base_similarity * self.base_url_weight +
                             query_similarity * self.params_weight)

        return {
            'base_similarity': base_similarity,
            'query_similarity': query_similarity,
            'full_similarity': full_similarity,
            'base_exact_match': base_exact_match,
            'composite_score': composite_score,
            'is_match': composite_score >= self.similarity_threshold,
            'details': {
                'base_similarity_seq': base_similarity_seq,
                'base_similarity_jaccard': base_similarity_jaccard,
                'base_similarity_levenshtein': base_similarity_levenshtein,
                'full_similarity_seq': full_similarity_seq,
                'full_similarity_jaccard': full_similarity_jaccard,
                'full_similarity_levenshtein': full_similarity_levenshtein
            }
        }

    def find_best_match(self, target_url: str, candidate_urls: List[str]) -> Optional[Tuple[str, Dict[str, float]]]:
        """
        åœ¨å€™é€‰URLåˆ—è¡¨ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…

        Args:
            target_url: ç›®æ ‡URL
            candidate_urls: å€™é€‰URLåˆ—è¡¨

        Returns:
            æœ€ä½³åŒ¹é…çš„URLå’Œç›¸ä¼¼åº¦ç»“æœï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…è¿”å›None
        """
        best_match = None
        best_score = 0.0
        best_result = None

        for candidate_url in candidate_urls:
            result = self.calculate_url_similarity(target_url, candidate_url)

            if result['composite_score'] > best_score:
                best_score = result['composite_score']
                best_match = candidate_url
                best_result = result

        # åªè¿”å›è¶…è¿‡é˜ˆå€¼çš„åŒ¹é…
        if best_score >= self.similarity_threshold:
            return best_match, best_result

        return None

    def set_similarity_threshold(self, threshold: float):
        """è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼"""
        self.similarity_threshold = max(0.0, min(1.0, threshold))

    def set_weights(self, base_url_weight: float, params_weight: float):
        """è®¾ç½®æƒé‡"""
        total = base_url_weight + params_weight
        if total > 0:
            self.base_url_weight = base_url_weight / total
            self.params_weight = params_weight / total


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    matcher = URLMatcher()

    # æµ‹è¯•URL
    url1 = "https://www.cmbwinglungbank.com/ibanking/McpCSReqServlet?dse_operationName=NbMsgMsgboxDspProc&dse_processorState=initial&dse_nextEventName=initial.logon&dse_sessionId=AAARCXAYDPFGIYHQBQAJCIBUHGDGIJHZABFNAQHD&mcp_language=cn&dse_pageId=1&dse_parentContextName="
    url2 = "https://www.cmbwinglungbank.com/ibanking/McpCSReqServlet?dse_operationName=NbMsgMsgboxDspProc&dse_processorState=initial&dse_nextEventName=initial.logon&dse_sessionId=DIFFERENT_SESSION_ID&mcp_language=cn&dse_pageId=1&dse_parentContextName="
    url3 = "https://www.cmbwinglungbank.com/ibanking/McpCSReqServlet?jspName=/accountmanagement/NbBkgWel.jsp&dse_sessionId=ANOTHER_SESSION&mcp_funcId=Acm&mcp_language=cn"
    url4 = "https://example.com/api/different"

    print("ğŸ§ª URLåŒ¹é…æµ‹è¯•")
    print("=" * 50)

    # æµ‹è¯•1: ç›¸åŒåŸºç¡€URLï¼Œä¸åŒå‚æ•°
    result = matcher.calculate_url_similarity(url1, url2)
    print(f"æµ‹è¯•1 - ç›¸åŒåŸºç¡€URLï¼Œä¸åŒå‚æ•°:")
    print(f"  åŸºç¡€URLåŒ¹é…: {result['base_exact_match']}")
    print(f"  ç»¼åˆè¯„åˆ†: {result['composite_score']:.3f}")
    print(f"  æ˜¯å¦åŒ¹é…: {result['is_match']}")
    print()

    # æµ‹è¯•2: ç›¸åŒåŸºç¡€URLï¼Œå®Œå…¨ä¸åŒå‚æ•°
    result = matcher.calculate_url_similarity(url1, url3)
    print(f"æµ‹è¯•2 - ç›¸åŒåŸºç¡€URLï¼Œå®Œå…¨ä¸åŒå‚æ•°:")
    print(f"  åŸºç¡€URLåŒ¹é…: {result['base_exact_match']}")
    print(f"  ç»¼åˆè¯„åˆ†: {result['composite_score']:.3f}")
    print(f"  æ˜¯å¦åŒ¹é…: {result['is_match']}")
    print()

    # æµ‹è¯•3: å®Œå…¨ä¸åŒURL
    result = matcher.calculate_url_similarity(url1, url4)
    print(f"æµ‹è¯•3 - å®Œå…¨ä¸åŒURL:")
    print(f"  åŸºç¡€URLåŒ¹é…: {result['base_exact_match']}")
    print(f"  ç»¼åˆè¯„åˆ†: {result['composite_score']:.3f}")
    print(f"  æ˜¯å¦åŒ¹é…: {result['is_match']}")
    print()

    # æµ‹è¯•4: æœ€ä½³åŒ¹é…æŸ¥æ‰¾
    candidates = [url2, url3, url4]
    best_match = matcher.find_best_match(url1, candidates)
    if best_match:
        print(f"æœ€ä½³åŒ¹é…: {best_match[0]}")
        print(f"åŒ¹é…è¯„åˆ†: {best_match[1]['composite_score']:.3f}")
    else:
        print("æœªæ‰¾åˆ°åŒ¹é…çš„URL")
