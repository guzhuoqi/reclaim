#!/usr/bin/env python3
"""
ç‰¹å¾åº“ä¸mitmproxy2swaggeré›†æˆè„šæœ¬
Feature Library Integration with mitmproxy2swagger

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†å¦‚ä½•å°†ç‰¹å¾åº“æ’ä»¶æ— ç¼é›†æˆåˆ°ç°æœ‰çš„mitmproxy2swaggerå·¥ä½œæµä¸­ã€‚
æ”¯æŒå¤šç§é›†æˆæ–¹å¼ï¼ŒåŒ…æ‹¬ç›´æ¥é›†æˆã€æ’ä»¶æ¨¡å¼å’Œæ‰©å±•æ¨¡å¼ã€‚

ä½¿ç”¨æ–¹å¼ï¼š
1. ç›´æ¥é›†æˆæ¨¡å¼ï¼špython3 integrate_with_mitmproxy2swagger.py --mode direct --input flows.mitm
2. æ’ä»¶æ¨¡å¼ï¼špython3 integrate_with_mitmproxy2swagger.py --mode plugin --input flows.mitm
3. æ‰©å±•æ¨¡å¼ï¼špython3 integrate_with_mitmproxy2swagger.py --mode extension --input flows.mitm
"""

import os
import sys
import json
import argparse
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir.parent.parent))
sys.path.append(str(current_dir.parent))
sys.path.append(str(current_dir))

# å¯¼å…¥mitmproxy2swaggeræ ¸å¿ƒæ¨¡å—
from mitmproxy2swagger.mitmproxy_capture_reader import MitmproxyCaptureReader

# å¯¼å…¥æˆ‘ä»¬çš„æ’ä»¶ç³»ç»Ÿ
from plugin_manager import initialize_plugin_system, plugin_manager
from feature_library_plugin import FeatureLibraryPlugin


class MitmproxySwaggerIntegrator:
    """mitmproxy2swaggeré›†æˆå™¨"""

    def __init__(self, integration_mode: str = "plugin"):
        """åˆå§‹åŒ–é›†æˆå™¨

        Args:
            integration_mode: é›†æˆæ¨¡å¼ (direct, plugin, extension)
        """
        self.integration_mode = integration_mode
        self.logger = logging.getLogger(__name__)

        # è®¾ç½®æ—¥å¿—
        self.setup_logging()

        # æ ¹æ®æ¨¡å¼åˆå§‹åŒ–ç»„ä»¶
        self.initialize_components()

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½® - åªè¾“å‡ºåˆ°æ§åˆ¶å°"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler()
            ]
        )

    def initialize_components(self):
        """æ ¹æ®é›†æˆæ¨¡å¼åˆå§‹åŒ–ç»„ä»¶"""
        if self.integration_mode == "direct":
            # ç›´æ¥é›†æˆæ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨ç‰¹å¾åº“ç»„ä»¶
            from ai_analysis_features.financial_api_analyzer import FinancialAPIAnalyzer
            from filter_features.api_value_filter import APIValueFilter

            self.analyzer = FinancialAPIAnalyzer()
            self.filter = APIValueFilter()
            self.logger.info("âœ… ç›´æ¥é›†æˆæ¨¡å¼åˆå§‹åŒ–å®Œæˆ")

        elif self.integration_mode == "plugin":
            # æ’ä»¶æ¨¡å¼ï¼šä½¿ç”¨æ’ä»¶ç®¡ç†å™¨
            success = initialize_plugin_system(str(current_dir))
            if success:
                self.plugin_manager = plugin_manager
                self.logger.info("âœ… æ’ä»¶æ¨¡å¼åˆå§‹åŒ–å®Œæˆ")
            else:
                raise Exception("æ’ä»¶ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")

        elif self.integration_mode == "extension":
            # æ‰©å±•æ¨¡å¼ï¼šå°è¯•é›†æˆåˆ°ç°æœ‰çš„mitmproxy2swaggeræ‰©å±•ç‚¹
            self.initialize_extension_mode()

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é›†æˆæ¨¡å¼: {self.integration_mode}")

    def initialize_extension_mode(self):
        """åˆå§‹åŒ–æ‰©å±•æ¨¡å¼"""
        try:
            # å°è¯•é›†æˆåˆ°ç°æœ‰çš„ExtractorRegistry
            from enhanced_mitmproxy2swagger.balance_data_extractor import extractor_registry
            from feature_library_plugin import FeatureLibraryExtractor

            # æ³¨å†Œæˆ‘ä»¬çš„æå–å™¨
            feature_extractor = FeatureLibraryExtractor()
            extractor_registry.register(feature_extractor)

            self.extractor_registry = extractor_registry
            self.logger.info("âœ… æ‰©å±•æ¨¡å¼åˆå§‹åŒ–å®Œæˆ - å·²æ³¨å†Œåˆ°ExtractorRegistry")

        except ImportError:
            self.logger.warning("âš ï¸  ExtractorRegistryä¸å¯ç”¨ï¼Œå›é€€åˆ°æ’ä»¶æ¨¡å¼")
            self.integration_mode = "plugin"
            self.initialize_components()

    def process_mitm_file(self, mitm_file_path: str, output_file: str = None) -> Dict[str, Any]:
        """å¤„ç†mitmæ–‡ä»¶

        Args:
            mitm_file_path: mitmæ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            å¤„ç†ç»“æœ
        """
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"integrated_results_{timestamp}.json"

        self.logger.info(f"ğŸš€ å¼€å§‹å¤„ç†mitmæ–‡ä»¶: {mitm_file_path}")
        self.logger.info(f"ğŸ“Š é›†æˆæ¨¡å¼: {self.integration_mode}")

        # æ ¹æ®é›†æˆæ¨¡å¼é€‰æ‹©å¤„ç†æ–¹æ³•
        if self.integration_mode == "direct":
            return self._process_direct_mode(mitm_file_path, output_file)
        elif self.integration_mode == "plugin":
            return self._process_plugin_mode(mitm_file_path, output_file)
        elif self.integration_mode == "extension":
            return self._process_extension_mode(mitm_file_path, output_file)

    def _process_direct_mode(self, mitm_file_path: str, output_file: str) -> Dict[str, Any]:
        """ç›´æ¥é›†æˆæ¨¡å¼å¤„ç†"""
        results = {
            "mode": "direct",
            "input_file": mitm_file_path,
            "output_file": output_file,
            "processed_flows": 0,
            "valuable_apis": 0,
            "extracted_data": []
        }

        try:
            # è¯»å–mitmæ–‡ä»¶
            capture_reader = MitmproxyCaptureReader(mitm_file_path)

            # ğŸ¯ ç¬¬ä¸€éï¼šæ”¶é›†æ‰€æœ‰æµæ•°æ®ç”¨äºç™»å½•åˆ†æ
            all_flows = []
            for flow_wrapper in capture_reader.captured_requests():
                results["processed_flows"] += 1

                # è·å–å®Œæ•´çš„æµä¿¡æ¯
                url = flow_wrapper.get_url()

                # å®‰å…¨åœ°è·å–å“åº”ä½“ï¼Œå¤„ç†ç¼–ç é—®é¢˜
                try:
                    response_body = flow_wrapper.get_response_body()
                except ValueError as e:
                    if 'Invalid Content-Encoding' in str(e):
                        self.logger.warning(f"âš ï¸  è·³è¿‡ç¼–ç æœ‰é—®é¢˜çš„å“åº”: {url}")
                        continue
                    else:
                        raise

                # æ„å»ºæµæ•°æ®
                flow_data = {
                    'url': url,
                    'method': flow_wrapper.get_method(),
                    'request_headers': flow_wrapper.get_request_headers(),
                    'request_body': flow_wrapper.get_request_body(),
                    'response_headers': flow_wrapper.get_response_headers(),
                    'response_body': response_body,
                    'status_code': flow_wrapper.get_response_status_code()
                }
                all_flows.append(flow_data)

            # ğŸ¯ æ‰§è¡Œå®Œæ•´çš„ç™»å½•APIåˆ†æ
            login_analysis = self.analyzer.analyze_login_apis(all_flows)
            results["login_analysis"] = login_analysis

            # ğŸ¯ ç¬¬äºŒéï¼šå¯¹æœ‰ä»·å€¼çš„APIè¿›è¡Œç‰¹å¾åˆ†æ
            for flow_data in all_flows:
                url = flow_data['url']
                response_body = flow_data['response_body']

                if not response_body:
                    continue

                # è§£ç å“åº”å†…å®¹
                response_content = response_body.decode('utf-8', errors='ignore')

                # ä½¿ç”¨ç‰¹å¾åº“åˆ†æ
                analysis_result = self.analyzer.analyze_api(
                    url=url,
                    response_content=response_content
                )

                # åªå¤„ç†æœ‰ä»·å€¼çš„API
                if analysis_result.priority_level in ["medium", "high", "critical"]:
                    results["valuable_apis"] += 1

                    # æå–æ•°æ®
                    extracted_item = {
                        "url": url,
                        "institution": analysis_result.institution,
                        "value_score": analysis_result.value_score,
                        "priority_level": analysis_result.priority_level,
                        "data_types": analysis_result.data_types,
                        "matched_patterns": analysis_result.matched_patterns,
                        # ğŸ¯ æ–°å¢ï¼šAPIåˆ†ç±»ä¿¡æ¯
                        "api_category": analysis_result.api_category,
                        "provider_worthy": analysis_result.provider_worthy,
                        # ğŸ¯ æ–°å¢ï¼šå“åº”æ•°æ®ä¿¡æ¯
                        "response_data": {
                            "status_code": flow_data.get('status_code'),
                            "content_type": flow_data.get('response_headers', {}).get('content-type', ''),
                            "content_length": len(response_body) if response_body else 0,
                            "content": response_content[:30000] if response_content else '',  # ä¿å­˜å‰30000å­—ç¬¦ç”¨äºåˆ†æ [VERSION-FIX-20250813]
                            "has_content": bool(response_content and len(response_content.strip()) > 0)
                        }
                    }

                    results["extracted_data"].append(extracted_item)

            # ä¿å­˜ç»“æœ
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)

            self.logger.info(f"âœ… ç›´æ¥æ¨¡å¼å¤„ç†å®Œæˆ: {results['valuable_apis']}/{results['processed_flows']} æœ‰ä»·å€¼API")
            return results

        except Exception as e:
            self.logger.error(f"âŒ ç›´æ¥æ¨¡å¼å¤„ç†å¤±è´¥: {e}")
            results["error"] = str(e)
            return results

    def _process_plugin_mode(self, mitm_file_path: str, output_file: str) -> Dict[str, Any]:
        """æ’ä»¶æ¨¡å¼å¤„ç†"""
        results = {
            "mode": "plugin",
            "input_file": mitm_file_path,
            "output_file": output_file,
            "plugins_used": [],
            "processed_flows": 0,
            "plugin_results": {}
        }

        try:
            # è·å–å·²åŠ è½½çš„æ’ä»¶
            loaded_plugins = self.plugin_manager.list_plugins()
            results["plugins_used"] = list(loaded_plugins.keys())

            # è¯»å–mitmæ–‡ä»¶
            capture_reader = MitmproxyCaptureReader(mitm_file_path)

            for flow_wrapper in capture_reader.captured_requests():
                results["processed_flows"] += 1

                url = flow_wrapper.get_url()

                # å®‰å…¨åœ°è·å–å“åº”ä½“ï¼Œå¤„ç†ç¼–ç é—®é¢˜
                try:
                    response_body = flow_wrapper.get_response_body()
                except ValueError as e:
                    if 'Invalid Content-Encoding' in str(e):
                        self.logger.warning(f"âš ï¸  è·³è¿‡ç¼–ç æœ‰é—®é¢˜çš„å“åº”: {url}")
                        continue
                    else:
                        raise

                if not response_body:
                    continue

                # å¯¹æ¯ä¸ªæ’ä»¶æ‰§è¡Œå¤„ç†
                for plugin_name, plugin_instance in self.plugin_manager.plugins.items():
                    if hasattr(plugin_instance, 'extractor'):
                        extractor = plugin_instance.extractor

                        # æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤„ç†
                        if extractor.can_handle(url, response_body):
                            # æå–æ•°æ®
                            extracted_data = extractor.extract_data(url, response_body)

                            if extracted_data:
                                if plugin_name not in results["plugin_results"]:
                                    results["plugin_results"][plugin_name] = []

                                results["plugin_results"][plugin_name].append({
                                    "url": url,
                                    "data": extracted_data
                                })

            # ä¿å­˜ç»“æœ
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)

            total_extractions = sum(len(data) for data in results["plugin_results"].values())
            self.logger.info(f"âœ… æ’ä»¶æ¨¡å¼å¤„ç†å®Œæˆ: {total_extractions} æ¬¡æ•°æ®æå–")
            return results

        except Exception as e:
            self.logger.error(f"âŒ æ’ä»¶æ¨¡å¼å¤„ç†å¤±è´¥: {e}")
            results["error"] = str(e)
            return results

    def _process_extension_mode(self, mitm_file_path: str, output_file: str) -> Dict[str, Any]:
        """æ‰©å±•æ¨¡å¼å¤„ç†"""
        results = {
            "mode": "extension",
            "input_file": mitm_file_path,
            "output_file": output_file,
            "processed_flows": 0,
            "enhanced_responses": 0,
            "extraction_results": []
        }

        try:
            # ä½¿ç”¨ç°æœ‰çš„ExtractorRegistryå¤„ç†
            capture_reader = MitmproxyCaptureReader(mitm_file_path)

            for flow_wrapper in capture_reader.captured_requests():
                results["processed_flows"] += 1

                url = flow_wrapper.get_url()

                # å®‰å…¨åœ°è·å–å“åº”ä½“ï¼Œå¤„ç†ç¼–ç é—®é¢˜
                try:
                    response_body = flow_wrapper.get_response_body()
                except ValueError as e:
                    if 'Invalid Content-Encoding' in str(e):
                        self.logger.warning(f"âš ï¸  è·³è¿‡ç¼–ç æœ‰é—®é¢˜çš„å“åº”: {url}")
                        continue
                    else:
                        raise

                if not response_body:
                    continue

                # ä½¿ç”¨ExtractorRegistryæŸ¥æ‰¾åˆé€‚çš„æå–å™¨
                extractor = self.extractor_registry.find_extractor(url, response_body)

                if extractor:
                    # æå–å¢å¼ºæ•°æ®
                    extracted_data, schema_enhancement = self.extractor_registry.extract_enhanced_data(url, response_body)

                    if extracted_data:
                        results["enhanced_responses"] += 1
                        results["extraction_results"].append({
                            "url": url,
                            "extractor_type": extractor.__class__.__name__,
                            "extracted_data": extracted_data,
                            "schema_enhancement": schema_enhancement
                        })

            # ä¿å­˜ç»“æœ
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)

            self.logger.info(f"âœ… æ‰©å±•æ¨¡å¼å¤„ç†å®Œæˆ: {results['enhanced_responses']}/{results['processed_flows']} å¢å¼ºå“åº”")
            return results

        except Exception as e:
            self.logger.error(f"âŒ æ‰©å±•æ¨¡å¼å¤„ç†å¤±è´¥: {e}")
            results["error"] = str(e)
            return results

    def get_integration_status(self) -> Dict[str, Any]:
        """è·å–é›†æˆçŠ¶æ€"""
        status = {
            "integration_mode": self.integration_mode,
            "timestamp": datetime.now().isoformat()
        }

        if self.integration_mode == "plugin":
            status["plugin_manager_status"] = self.plugin_manager.get_status_report()
        elif self.integration_mode == "extension":
            status["extractor_registry_available"] = hasattr(self, 'extractor_registry')

        return status


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description='ç‰¹å¾åº“ä¸mitmproxy2swaggeré›†æˆ')
    parser.add_argument('--mode', '-m', choices=['direct', 'plugin', 'extension'],
                       default='plugin', help='é›†æˆæ¨¡å¼')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥çš„mitmæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--status', '-s', action='store_true', help='æ˜¾ç¤ºé›†æˆçŠ¶æ€')

    args = parser.parse_args()

    try:
        # åˆ›å»ºé›†æˆå™¨
        integrator = MitmproxySwaggerIntegrator(args.mode)

        if args.status:
            # æ˜¾ç¤ºçŠ¶æ€
            status = integrator.get_integration_status()
            print("ğŸ“Š é›†æˆçŠ¶æ€:")
            print(json.dumps(status, indent=2, ensure_ascii=False))

        # å¤„ç†æ–‡ä»¶
        result = integrator.process_mitm_file(args.input, args.output)

        if "error" not in result:
            print(f"âœ… å¤„ç†æˆåŠŸ!")
            print(f"ğŸ“Š æ¨¡å¼: {result['mode']}")
            print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {result['output_file']}")

            if result['mode'] == 'direct':
                print(f"ğŸ¯ æœ‰ä»·å€¼API: {result['valuable_apis']}/{result['processed_flows']}")
            elif result['mode'] == 'plugin':
                total_extractions = sum(len(data) for data in result['plugin_results'].values())
                print(f"ğŸ”Œ æ’ä»¶æå–: {total_extractions} æ¬¡")
            elif result['mode'] == 'extension':
                print(f"ğŸš€ å¢å¼ºå“åº”: {result['enhanced_responses']}/{result['processed_flows']}")
        else:
            print(f"âŒ å¤„ç†å¤±è´¥: {result['error']}")

    except Exception as e:
        print(f"âŒ é›†æˆå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
