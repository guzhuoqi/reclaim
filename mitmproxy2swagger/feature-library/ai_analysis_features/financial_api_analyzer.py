#!/usr/bin/env python3
"""
é‡‘èAPIç‰¹å¾åˆ†æå™¨
Financial API Feature Analyzer

åŸºäºç‰¹å¾åº“è¯†åˆ«æœ‰ä»·å€¼çš„é‡‘èAPIç«¯ç‚¹
ç”¨äºåˆ†ææŠ“åŒ…æ–‡ä»¶ä¸­çš„é‡‘èæœºæ„APIï¼Œé‡ç‚¹è¯†åˆ«è´¦æˆ·ä¿¡æ¯ã€èµ„äº§ä¿¡æ¯ã€ä½™é¢ä¿¡æ¯ç­‰æ ¸å¿ƒæ•°æ®API

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. åŸºäºåŸŸåè¯†åˆ«é‡‘èæœºæ„
2. åŸºäºURLæ¨¡å¼åŒ¹é…æœ‰ä»·å€¼çš„APIç«¯ç‚¹
3. æ£€æµ‹è®¤è¯ä¿¡æ¯çš„å­˜åœ¨
4. åˆ†æå“åº”å†…å®¹ä¸­çš„é‡‘èæ•°æ®
5. ç»¼åˆè¯„åˆ†å’Œä¼˜å…ˆçº§æ’åº
"""

import json
import re
import logging
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from urllib.parse import urlparse
from dataclasses import dataclass
from html.parser import HTMLParser
import html


class FinancialHTMLParser(HTMLParser):
    """ä¸“é—¨ç”¨äºè§£æHTMLä¸­é‡‘èæ•°æ®çš„è§£æå™¨"""

    def __init__(self):
        super().__init__()
        self.financial_data = []
        self.current_tag = None
        self.current_attrs = {}
        self.text_content = []

        # é‡‘èæ•°æ®ç›¸å…³çš„æ ‡ç­¾å’Œå±æ€§
        self.financial_indicators = {
            'currency_codes': ['HKD', 'USD', 'CNY', 'EUR', 'GBP', 'JPY', 'AUD', 'CAD', 'SGD'],
            'amount_patterns': [
                r'\$[\d,]+\.?\d*',  # $1,234.56
                r'[\d,]+\.?\d*\s*(HKD|USD|CNY|EUR|GBP|JPY)',  # 1,234.56 HKD
                r'(HKD|USD|CNY|EUR|GBP|JPY)\s*[\d,]+\.?\d*',  # HKD 1,234.56
                r'[\d,]+\.?\d{2}',  # 1,234.56
            ],
            'account_patterns': [
                r'\d{4,20}',  # è´¦æˆ·å·ç 
                r'[A-Z]{2,4}\d{6,16}',  # é“¶è¡Œè´¦æˆ·æ ¼å¼
            ],
            'financial_keywords': [
                'balance', 'amount', 'value', 'total', 'available', 'current',
                'account', 'portfolio', 'investment', 'asset', 'equity',
                'ä½™é¢', 'é‡‘é¢', 'æ€»é¢', 'å¯ç”¨', 'å½“å‰', 'è´¦æˆ·', 'æŠ•èµ„ç»„åˆ', 'èµ„äº§'
            ]
        }

    def handle_starttag(self, tag, attrs):
        self.current_tag = tag
        self.current_attrs = dict(attrs)

        # æ£€æŸ¥å±æ€§ä¸­çš„é‡‘èæ•°æ®
        for attr_name, attr_value in attrs:
            if attr_value:
                self._analyze_text_for_financial_data(attr_value, f"attr:{attr_name}")

    def handle_data(self, data):
        if data.strip():
            self.text_content.append(data.strip())
            self._analyze_text_for_financial_data(data.strip(), f"tag:{self.current_tag}")

    def _analyze_text_for_financial_data(self, text, source):
        """åˆ†ææ–‡æœ¬ä¸­çš„é‡‘èæ•°æ®"""
        text_lower = text.lower()

        # æ£€æŸ¥è´§å¸ä»£ç 
        for currency in self.financial_indicators['currency_codes']:
            if currency.lower() in text_lower or currency in text:
                self.financial_data.append({
                    'type': 'currency',
                    'value': currency,
                    'source': source,
                    'context': text[:100]
                })

        # æ£€æŸ¥é‡‘é¢æ¨¡å¼
        for pattern in self.financial_indicators['amount_patterns']:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                self.financial_data.append({
                    'type': 'amount',
                    'value': match,
                    'source': source,
                    'context': text[:100]
                })

        # æ£€æŸ¥è´¦æˆ·æ¨¡å¼
        for pattern in self.financial_indicators['account_patterns']:
            matches = re.findall(pattern, text)
            for match in matches:
                # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯è´¦æˆ·å·çš„æ•°å­—ï¼ˆå¦‚å¹´ä»½ã€ç”µè¯ç­‰ï¼‰
                if len(match) >= 6 and not match.startswith(('19', '20')):
                    self.financial_data.append({
                        'type': 'account',
                        'value': match,
                        'source': source,
                        'context': text[:100]
                    })

        # æ£€æŸ¥é‡‘èå…³é”®å­—
        for keyword in self.financial_indicators['financial_keywords']:
            if keyword in text_lower:
                self.financial_data.append({
                    'type': 'keyword',
                    'value': keyword,
                    'source': source,
                    'context': text[:100]
                })

    def get_financial_data(self):
        """è·å–è§£æå‡ºçš„é‡‘èæ•°æ®"""
        return self.financial_data

    def get_text_content(self):
        """è·å–æ‰€æœ‰æ–‡æœ¬å†…å®¹"""
        return ' '.join(self.text_content)


@dataclass
class APIAnalysisResult:
    """APIåˆ†æç»“æœ"""
    url: str
    institution: str = ""
    institution_type: str = ""
    matched_patterns: List[str] = None
    value_score: int = 0
    priority_level: str = "low"
    data_types: List[str] = None
    authentication_detected: bool = False
    response_contains_financial_data: bool = False
    analysis_details: Dict[str, Any] = None
    # ğŸ¯ æ–°å¢ï¼šAPIåˆ†ç±»å­—æ®µ
    api_category: str = "unknown"  # query, auth, resource, unknown
    provider_worthy: bool = False  # æ˜¯å¦å€¼å¾—ç”Ÿæˆprovider

    def __post_init__(self):
        if self.matched_patterns is None:
            self.matched_patterns = []
        if self.data_types is None:
            self.data_types = []
        if self.analysis_details is None:
            self.analysis_details = {}


class FinancialAPIAnalyzer:
    """é‡‘èAPIç‰¹å¾åˆ†æå™¨"""

    def __init__(self, features_config_path: str = None):
        """åˆå§‹åŒ–åˆ†æå™¨

        Args:
            features_config_path: ç‰¹å¾åº“é…ç½®æ–‡ä»¶è·¯å¾„
        """
        if features_config_path is None:
            features_config_path = Path(__file__).parent / "financial_api_features.json"

        self.features_config_path = Path(features_config_path)
        self.features_config = {}

        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)

        # åŠ è½½ç‰¹å¾é…ç½®
        self.load_features_config()

    def load_features_config(self) -> bool:
        """åŠ è½½ç‰¹å¾é…ç½®"""
        try:
            if not self.features_config_path.exists():
                self.logger.error(f"ç‰¹å¾é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.features_config_path}")
                return False

            with open(self.features_config_path, 'r', encoding='utf-8') as f:
                self.features_config = json.load(f)

            self.logger.info(f"ç‰¹å¾é…ç½®åŠ è½½æˆåŠŸ: {self.features_config_path}")
            return True

        except Exception as e:
            self.logger.error(f"åŠ è½½ç‰¹å¾é…ç½®å¤±è´¥: {e}")
            return False

    def identify_institution(self, url: str) -> Tuple[str, str, str]:
        """è¯†åˆ«é‡‘èæœºæ„

        Args:
            url: API URL

        Returns:
            Tuple[str, str, str]: (æœºæ„åç§°, æœºæ„ç±»å‹, åŒ¹é…çš„åŸŸå)
        """
        parsed_url = urlparse(url.lower())
        domain = parsed_url.netloc

        # æ£€æŸ¥å„ç±»é‡‘èæœºæ„
        institution_categories = [
            ("hong_kong_banks", "é¦™æ¸¯é“¶è¡Œ"),
            ("us_european_banks", "æ¬§ç¾é“¶è¡Œ"),
            ("china_mainland_banks", "ä¸­å›½å¤§é™†é“¶è¡Œ"),
            ("global_investment_banks", "å…¨çƒæŠ•èµ„é“¶è¡Œ"),
            ("brokerage_firms", "åˆ¸å•†"),
            ("cryptocurrency_exchanges", "åŠ å¯†è´§å¸äº¤æ˜“æ‰€"),
            ("payment_platforms", "æ”¯ä»˜å¹³å°"),
            ("insurance_companies", "ä¿é™©å…¬å¸"),
            ("fintech_companies", "é‡‘èç§‘æŠ€å…¬å¸")
        ]

        for category_key, category_name in institution_categories:
            category_data = self.features_config.get(category_key, {})
            institutions = category_data.get("institutions", {})

            for inst_key, inst_data in institutions.items():
                domains = inst_data.get("domains", [])
                for inst_domain in domains:
                    if inst_domain.lower() in domain:
                        return inst_data.get("name", inst_key), category_name, inst_domain

        return "", "", ""

    def match_api_patterns(self, url: str, institution_data: Dict[str, Any]) -> Tuple[List[str], int]:
        """åŒ¹é…APIæ¨¡å¼

        Args:
            url: API URL
            institution_data: æœºæ„æ•°æ®

        Returns:
            Tuple[List[str], int]: (åŒ¹é…çš„æ¨¡å¼åˆ—è¡¨, åŠ åˆ†å€¼)
        """
        matched_patterns = []
        total_bonus = 0

        api_patterns = institution_data.get("api_patterns", {})
        value_indicators = institution_data.get("value_indicators", {})

        for pattern_category, patterns in api_patterns.items():
            for pattern in patterns:
                try:
                    if re.search(pattern, url, re.IGNORECASE):
                        matched_patterns.append(f"{pattern_category}:{pattern}")
                        break  # æ¯ä¸ªç±»åˆ«åªåŒ¹é…ä¸€æ¬¡
                except re.error:
                    continue

        # ä¸¥æ ¼è®¡ç®—åŠ åˆ†ï¼šéœ€è¦åŒ¹é…å¤šä¸ªæ¨¡å¼æ‰ç»™é«˜åˆ†
        if matched_patterns:
            bonus_weight = value_indicators.get("bonus_weight", 0)

            # æ ¹æ®åŒ¹é…çš„æ¨¡å¼æ•°é‡è°ƒæ•´åˆ†æ•°
            pattern_count = len(matched_patterns)
            if pattern_count >= 3:  # åŒ¹é…3ä¸ªæˆ–ä»¥ä¸Šæ¨¡å¼ï¼Œç»™æ»¡åˆ†
                total_bonus = bonus_weight
            elif pattern_count == 2:  # åŒ¹é…2ä¸ªæ¨¡å¼ï¼Œç»™70%åˆ†æ•°
                total_bonus = int(bonus_weight * 0.7)
            elif pattern_count == 1:  # åªåŒ¹é…1ä¸ªæ¨¡å¼ï¼Œç»™40%åˆ†æ•°
                total_bonus = int(bonus_weight * 0.4)
            else:
                total_bonus = 0

        return matched_patterns, total_bonus

    def match_universal_patterns(self, url: str) -> Tuple[List[str], int]:
        """åŒ¹é…é€šç”¨æ¨¡å¼

        Args:
            url: API URL

        Returns:
            Tuple[List[str], int]: (åŒ¹é…çš„æ¨¡å¼åˆ—è¡¨, åŠ åˆ†å€¼)
        """
        matched_patterns = []
        total_bonus = 0

        universal_patterns = self.features_config.get("universal_financial_patterns", {})

        for pattern_type, pattern_data in universal_patterns.items():
            if pattern_type == "description":
                continue

            patterns = pattern_data.get("patterns", [])
            bonus_weight = pattern_data.get("bonus_weight", 0)

            for pattern in patterns:
                try:
                    if re.search(pattern, url, re.IGNORECASE):
                        matched_patterns.append(f"universal:{pattern_type}:{pattern}")
                        break  # æ¯ä¸ªç±»å‹åªåŒ¹é…ä¸€æ¬¡
                except re.error:
                    continue

        # ä¸¥æ ¼è®¡ç®—é€šç”¨æ¨¡å¼åŠ åˆ†ï¼šéœ€è¦åŒ¹é…å¤šä¸ªç±»å‹æ‰ç»™åˆ†
        if len(matched_patterns) >= 2:  # è‡³å°‘åŒ¹é…2ä¸ªä¸åŒç±»å‹çš„æ¨¡å¼
            # è®¡ç®—æ€»åŠ åˆ†ï¼Œä½†é™åˆ¶æœ€å¤§å€¼
            for pattern_type, pattern_data in universal_patterns.items():
                if pattern_type == "description":
                    continue
                bonus_weight = pattern_data.get("bonus_weight", 0)
                # æ£€æŸ¥æ˜¯å¦æœ‰è¯¥ç±»å‹çš„åŒ¹é…
                if any(pattern_type in pattern for pattern in matched_patterns):
                    total_bonus += min(bonus_weight, 15)  # é™åˆ¶å•ä¸ªç±»å‹æœ€å¤§åŠ åˆ†

        return matched_patterns, total_bonus

    def check_strict_financial_keywords(self, url: str, response_content: str = "") -> Tuple[bool, List[str], int]:
        """æ£€æŸ¥ä¸¥æ ¼çš„é‡‘èå…³é”®å­—ç»„åˆ

        Args:
            url: API URL
            response_content: å“åº”å†…å®¹

        Returns:
            Tuple[bool, List[str], int]: (æ˜¯å¦æ»¡è¶³ä¸¥æ ¼æ¡ä»¶, åŒ¹é…çš„å…³é”®å­—, åŠ åˆ†å€¼)
        """
        # å®šä¹‰ä¸¥æ ¼çš„é‡‘èå…³é”®å­—ç»„åˆ
        strict_keywords = {
            "account_operations": {
                "url_keywords": ["account", "acc", "balance", "overview", "summary"],
                "path_keywords": ["banking", "ibanking", "ebanking"],
                "tech_keywords": ["servlet", "api", "service"],
                "required_count": 2,  # è‡³å°‘éœ€è¦åŒ¹é…2ä¸ªä¸åŒç±»åˆ«
                "bonus": 40
            },
            "transaction_operations": {
                "url_keywords": ["transaction", "txn", "transfer", "payment", "history"],
                "path_keywords": ["banking", "ibanking", "ebanking"],
                "tech_keywords": ["servlet", "api", "service"],
                "required_count": 2,
                "bonus": 35
            },
            "authentication_operations": {
                "url_keywords": ["login", "logon", "auth", "verify", "token"],
                "path_keywords": ["banking", "ibanking", "ebanking", "security"],
                "tech_keywords": ["servlet", "api", "service"],
                "required_count": 2,
                "bonus": 30
            }
        }

        matched_keywords = []
        total_bonus = 0
        url_lower = url.lower()
        content_lower = response_content.lower() if response_content else ""

        for operation_type, criteria in strict_keywords.items():
            matched_categories = 0
            operation_matches = []

            # æ£€æŸ¥URLå…³é”®å­—
            url_matches = [kw for kw in criteria["url_keywords"] if kw in url_lower]
            if url_matches:
                matched_categories += 1
                operation_matches.extend([f"url:{kw}" for kw in url_matches])

            # æ£€æŸ¥è·¯å¾„å…³é”®å­—
            path_matches = [kw for kw in criteria["path_keywords"] if kw in url_lower]
            if path_matches:
                matched_categories += 1
                operation_matches.extend([f"path:{kw}" for kw in path_matches])

            # æ£€æŸ¥æŠ€æœ¯å…³é”®å­—
            tech_matches = [kw for kw in criteria["tech_keywords"] if kw in url_lower]
            if tech_matches:
                matched_categories += 1
                operation_matches.extend([f"tech:{kw}" for kw in tech_matches])

            # æ£€æŸ¥å“åº”å†…å®¹å…³é”®å­—ï¼ˆå¦‚æœæœ‰ï¼‰
            if content_lower:
                content_matches = [kw for kw in criteria["url_keywords"] if kw in content_lower]
                if content_matches:
                    matched_categories += 1
                    operation_matches.extend([f"content:{kw}" for kw in content_matches])

            # å¦‚æœæ»¡è¶³æœ€ä½è¦æ±‚ï¼Œç»™äºˆåŠ åˆ†
            if matched_categories >= criteria["required_count"]:
                matched_keywords.extend([f"{operation_type}:{match}" for match in operation_matches])
                total_bonus += criteria["bonus"]

        is_strict_match = len(matched_keywords) > 0
        return is_strict_match, matched_keywords, total_bonus

    def detect_authentication(self, headers: Dict[str, str] = None,
                            cookies: Dict[str, str] = None,
                            url_params: Dict[str, str] = None) -> Tuple[bool, List[str]]:
        """æ£€æµ‹è®¤è¯ä¿¡æ¯

        Args:
            headers: HTTPå¤´éƒ¨
            cookies: Cookieä¿¡æ¯
            url_params: URLå‚æ•°

        Returns:
            Tuple[bool, List[str]]: (æ˜¯å¦æ£€æµ‹åˆ°è®¤è¯, æ£€æµ‹åˆ°çš„è®¤è¯ç±»å‹)
        """
        auth_indicators = self.features_config.get("authentication_indicators", {})
        detected_auth = []

        if headers:
            auth_headers = auth_indicators.get("auth_headers", [])
            for header_name in auth_headers:
                if header_name.lower() in [h.lower() for h in headers.keys()]:
                    detected_auth.append(f"header:{header_name}")

        if cookies:
            session_patterns = auth_indicators.get("session_patterns", [])
            for cookie_name in cookies.keys():
                for pattern in session_patterns:
                    if pattern.lower() in cookie_name.lower():
                        detected_auth.append(f"cookie:{pattern}")

        if url_params:
            auth_parameters = auth_indicators.get("auth_parameters", [])
            for param_name in url_params.keys():
                for auth_param in auth_parameters:
                    if auth_param.lower() in param_name.lower():
                        detected_auth.append(f"param:{auth_param}")

        return len(detected_auth) > 0, detected_auth

    def analyze_response_content(self, response_content: str) -> Tuple[bool, List[str]]:
        """åˆ†æå“åº”å†…å®¹ï¼ˆæ”¯æŒJSONå’ŒHTMLï¼‰

        Args:
            response_content: å“åº”å†…å®¹

        Returns:
            Tuple[bool, List[str]]: (æ˜¯å¦åŒ…å«é‡‘èæ•°æ®, åŒ¹é…çš„å­—æ®µåˆ—è¡¨)
        """
        if not response_content:
            return False, []

        content_indicators = self.features_config.get("response_content_indicators", {})
        matched_fields = []

        # 1. æ£€æŸ¥é«˜ä»·å€¼å­—æ®µï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        high_value_fields = content_indicators.get("high_value_fields", [])
        for field in high_value_fields:
            if field.lower() in response_content.lower():
                matched_fields.append(f"field:{field}")

        # 2. æ£€æŸ¥é‡‘èæ•°æ®æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        financial_patterns = content_indicators.get("financial_data_patterns", [])
        for pattern in financial_patterns:
            try:
                if re.search(pattern, response_content, re.IGNORECASE):
                    matched_fields.append(f"pattern:{pattern}")
            except re.error:
                continue

        # 3. ğŸ¯ æ–°å¢ï¼šHTMLå†…å®¹è§£æ
        html_financial_data = self.analyze_html_content(response_content)
        matched_fields.extend(html_financial_data)

        # 4. ğŸ¯ æ–°å¢ï¼šJSONå†…å®¹æ·±åº¦è§£æ
        json_financial_data = self.analyze_json_content(response_content)
        matched_fields.extend(json_financial_data)

        return len(matched_fields) > 0, matched_fields

    def analyze_html_content(self, content: str) -> List[str]:
        """åˆ†æHTMLå†…å®¹ä¸­çš„é‡‘èæ•°æ® - ğŸ¯ ç²¾ç¡®éªŒè¯å®é™…å†…å®¹

        Args:
            content: HTMLå†…å®¹

        Returns:
            List[str]: åŒ¹é…çš„é‡‘èæ•°æ®æ¨¡å¼åˆ—è¡¨
        """
        matched_patterns = []

        # æ£€æŸ¥æ˜¯å¦ä¸ºHTMLå†…å®¹
        if not (content.strip().startswith('<') or '<html' in content.lower() or '<body' in content.lower()):
            return matched_patterns

        try:
            # ğŸ¯ ç²¾ç¡®éªŒè¯ï¼šåªæœ‰çœŸå®å­˜åœ¨ä¸”æœ‰æ„ä¹‰çš„æ•°æ®æ‰ç”Ÿæˆæ¨¡å¼
            verified_data = self._verify_html_financial_data(content)

            # æ ¹æ®éªŒè¯ç»“æœç”Ÿæˆç²¾ç¡®çš„æ¨¡å¼
            if verified_data['currencies']:
                for currency in verified_data['currencies']:
                    matched_patterns.append(f"html_currency:{currency}")
                matched_patterns.append(f"html_content:currency")

            if verified_data['amounts']:
                matched_patterns.append(f"html_content:amount")

            if verified_data['accounts']:
                matched_patterns.append(f"html_content:account")

            if verified_data['balance_indicators']:
                matched_patterns.append(f"html_content:balance")

            if verified_data['asset_indicators']:
                matched_patterns.append(f"html_content:asset")

            if verified_data['name_indicators']:
                matched_patterns.append(f"html_content:customer_name")

            print(f"ğŸ” HTMLç²¾ç¡®éªŒè¯ç»“æœ: è´§å¸{len(verified_data['currencies'])}ä¸ª, é‡‘é¢{len(verified_data['amounts'])}ä¸ª, è´¦æˆ·{len(verified_data['accounts'])}ä¸ª")

        except Exception as e:
            print(f"âš ï¸ HTMLè§£æå¤±è´¥: {e}")

        return matched_patterns

    def _verify_html_financial_data(self, content: str) -> dict:
        """ç²¾ç¡®éªŒè¯HTMLå†…å®¹ä¸­çš„é‡‘èæ•°æ®

        Args:
            content: HTMLå†…å®¹

        Returns:
            dict: éªŒè¯åçš„é‡‘èæ•°æ®
        """
        import re

        verified_data = {
            'currencies': set(),
            'amounts': set(),
            'accounts': set(),
            'balance_indicators': False,
            'asset_indicators': False,
            'name_indicators': False
        }

        # ğŸ¯ ç²¾ç¡®éªŒè¯è´§å¸ä»£ç  - å¿…é¡»åœ¨è¡¨æ ¼æˆ–æ˜ç¡®çš„é‡‘èä¸Šä¸‹æ–‡ä¸­
        currency_codes = ['HKD', 'USD', 'CNY', 'EUR', 'GBP', 'JPY', 'AUD', 'CAD', 'SGD']
        for currency in currency_codes:
            # æ£€æŸ¥è´§å¸ä»£ç æ˜¯å¦åœ¨è¡¨æ ¼å•å…ƒæ ¼ä¸­æˆ–ä¸é‡‘é¢ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¸­
            currency_patterns = [
                rf'<td[^>]*>{currency}</td>',  # è¡¨æ ¼å•å…ƒæ ¼ä¸­
                rf'<span[^>]*>{currency}</span>',  # spanæ ‡ç­¾ä¸­
                rf'{currency}\s*[0-9,]+\.?\d*',  # è´§å¸ä»£ç åè·Ÿæ•°å­—
                rf'[0-9,]+\.?\d*\s*{currency}',  # æ•°å­—åè·Ÿè´§å¸ä»£ç 
            ]

            for pattern in currency_patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    verified_data['currencies'].add(currency)
                    break

        # ğŸ¯ ç²¾ç¡®éªŒè¯é‡‘é¢æ ¼å¼ - å¿…é¡»æ˜¯çœŸå®çš„é‡‘é¢æ ¼å¼
        amount_patterns = [
            r'\$[0-9,]+\.[0-9]{2}',  # $1,234.56
            r'[0-9,]+\.[0-9]{2}\s*(HKD|USD|CNY|EUR|GBP|JPY)',  # 1,234.56 HKD
            r'(HKD|USD|CNY|EUR|GBP|JPY)\s*[0-9,]+\.[0-9]{2}',  # HKD 1,234.56
        ]

        for pattern in amount_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                verified_data['amounts'].update(matches[:5])  # æœ€å¤šè®°å½•5ä¸ª

        # ğŸ¯ ç²¾ç¡®éªŒè¯è´¦æˆ·å·ç  - æ’é™¤æ˜æ˜¾çš„æ—¥æœŸã€ç”µè¯ç­‰
        account_patterns = [
            r'\b\d{8,20}\b',  # 8-20ä½æ•°å­—
            r'\b[A-Z]{2,4}\d{8,16}\b',  # å­—æ¯+æ•°å­—æ ¼å¼
        ]

        for pattern in account_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                # æ’é™¤æ˜æ˜¾çš„æ—¥æœŸæ ¼å¼
                if not (match.startswith('20') and len(match) == 8):  # æ’é™¤20140715è¿™æ ·çš„æ—¥æœŸ
                    if not (match.startswith('19') and len(match) == 8):  # æ’é™¤19xxå¹´ä»½
                        verified_data['accounts'].add(match)

        # ğŸ¯ ç²¾ç¡®éªŒè¯ä½™é¢æŒ‡ç¤ºå™¨ - å¿…é¡»åœ¨é‡‘èä¸Šä¸‹æ–‡ä¸­
        balance_keywords = ['balance', 'available', 'current', 'ä½™é¢', 'å¯ç”¨', 'å½“å‰']
        balance_context_patterns = [
            r'(balance|available|current|ä½™é¢|å¯ç”¨|å½“å‰)[^<]*[0-9,]+\.?\d*',
            r'<td[^>]*>(balance|available|current|ä½™é¢|å¯ç”¨|å½“å‰)</td>',
        ]

        for pattern in balance_context_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                verified_data['balance_indicators'] = True
                break

        # ğŸ¯ ç²¾ç¡®éªŒè¯èµ„äº§æŒ‡ç¤ºå™¨
        asset_keywords = ['asset', 'portfolio', 'investment', 'equity', 'èµ„äº§', 'æŠ•èµ„ç»„åˆ', 'å‡€å€¼']
        for keyword in asset_keywords:
            if keyword in content.lower() and re.search(rf'{keyword}[^<]*[0-9,]+\.?\d*', content, re.IGNORECASE):
                verified_data['asset_indicators'] = True
                break

        # ğŸ¯ ç²¾ç¡®éªŒè¯å§“åæŒ‡ç¤ºå™¨
        name_keywords = ['customer', 'holder', 'name', 'å®¢æˆ·', 'æŒæœ‰äºº', 'å§“å']
        for keyword in name_keywords:
            if keyword in content.lower():
                verified_data['name_indicators'] = True
                break

        return verified_data

    def analyze_json_content(self, content: str) -> List[str]:
        """æ·±åº¦åˆ†æJSONå†…å®¹ä¸­çš„é‡‘èæ•°æ®

        Args:
            content: JSONå†…å®¹

        Returns:
            List[str]: åŒ¹é…çš„é‡‘èæ•°æ®æ¨¡å¼åˆ—è¡¨
        """
        matched_patterns = []

        # æ£€æŸ¥æ˜¯å¦ä¸ºJSONå†…å®¹
        content_stripped = content.strip()
        if not (content_stripped.startswith('{') or content_stripped.startswith('[')):
            return matched_patterns

        try:
            # è§£æJSON
            if content_stripped.startswith('{'):
                data = json.loads(content_stripped)
            elif content_stripped.startswith('['):
                data = json.loads(content_stripped)
                # å¦‚æœæ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ è¿›è¡Œåˆ†æ
                if data and isinstance(data, list) and len(data) > 0:
                    data = data[0]
                else:
                    return matched_patterns
            else:
                return matched_patterns

            # é€’å½’åˆ†æJSONç»“æ„
            self._analyze_json_object(data, matched_patterns, "")

            print(f"ğŸ” JSONè§£æç»“æœ: å‘ç°{len(matched_patterns)}ä¸ªé‡‘èæ•°æ®æ¨¡å¼")

        except (json.JSONDecodeError, Exception) as e:
            # ä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œå¿½ç•¥
            pass

        return matched_patterns

    def _analyze_json_object(self, obj, matched_patterns: List[str], path: str):
        """é€’å½’åˆ†æJSONå¯¹è±¡"""
        if isinstance(obj, dict):
            for key, value in obj.items():
                current_path = f"{path}.{key}" if path else key

                # åˆ†æé”®å
                self._analyze_json_key(key, matched_patterns)

                # åˆ†æå€¼
                if isinstance(value, (str, int, float)):
                    self._analyze_json_value(key, value, matched_patterns)
                elif isinstance(value, (dict, list)):
                    self._analyze_json_object(value, matched_patterns, current_path)

        elif isinstance(obj, list):
            for i, item in enumerate(obj):
                if isinstance(item, (dict, list)):
                    self._analyze_json_object(item, matched_patterns, f"{path}[{i}]")

    def _analyze_json_key(self, key: str, matched_patterns: List[str]):
        """åˆ†æJSONé”®å"""
        key_lower = key.lower()

        # è´§å¸ç›¸å…³ - ğŸ¯ JSONä¸“ç”¨æ¨¡å¼
        if any(currency_kw in key_lower for currency_kw in ['currency', 'curr', 'ccy']):
            if "json_content:currency" not in matched_patterns:
                matched_patterns.append("json_content:currency")

        # é‡‘é¢ç›¸å…³
        if any(amount_kw in key_lower for amount_kw in ['amount', 'value', 'price', 'cost']):
            if "json_content:amount" not in matched_patterns:
                matched_patterns.append("json_content:amount")

        # ä½™é¢ç›¸å…³
        if any(balance_kw in key_lower for balance_kw in ['balance', 'available', 'current']):
            if "json_content:balance" not in matched_patterns:
                matched_patterns.append("json_content:balance")

        # è´¦æˆ·ç›¸å…³
        if any(account_kw in key_lower for account_kw in ['account', 'acc', 'acct']):
            if "json_content:account" not in matched_patterns:
                matched_patterns.append("json_content:account")

        # ç”¨æˆ·ä¿¡æ¯ç›¸å…³
        if any(name_kw in key_lower for name_kw in ['name', 'customer', 'holder', 'user']):
            if "json_content:customer_name" not in matched_patterns:
                matched_patterns.append("json_content:customer_name")

        # èµ„äº§ç›¸å…³
        if any(asset_kw in key_lower for asset_kw in ['asset', 'portfolio', 'investment', 'equity']):
            if "json_content:asset" not in matched_patterns:
                matched_patterns.append("json_content:asset")

    def _analyze_json_value(self, key: str, value, matched_patterns: List[str]):
        """åˆ†æJSONå€¼"""
        if isinstance(value, str):
            value_upper = value.upper()

            # æ£€æŸ¥è´§å¸ä»£ç  - ğŸ¯ JSONä¸“ç”¨æ¨¡å¼
            currency_codes = ['HKD', 'USD', 'CNY', 'EUR', 'GBP', 'JPY', 'AUD', 'CAD', 'SGD']
            if value_upper in currency_codes:
                if "json_content:currency" not in matched_patterns:
                    matched_patterns.append("json_content:currency")
                matched_patterns.append(f"json_currency:{value_upper}")

        elif isinstance(value, (int, float)):
            # æ£€æŸ¥æ˜¯å¦ä¸ºé‡‘é¢ï¼ˆé€šè¿‡é”®ååˆ¤æ–­ï¼‰
            key_lower = key.lower()
            if any(money_kw in key_lower for money_kw in ['amount', 'balance', 'value', 'price', 'cost']):
                if "json_content:amount" not in matched_patterns:
                    matched_patterns.append("json_content:amount")
                if "json_content:balance" not in matched_patterns and 'balance' in key_lower:
                    matched_patterns.append("json_content:balance")

    def calculate_priority_level(self, score: int) -> str:
        """è®¡ç®—ä¼˜å…ˆçº§ç­‰çº§"""
        thresholds = self.features_config.get("analysis_configuration", {}).get("thresholds", {})

        critical_score = thresholds.get("critical_value_score", 80)
        high_score = thresholds.get("high_value_score", 50)
        min_score = thresholds.get("minimum_score", 20)

        if score >= critical_score:
            return "critical"
        elif score >= high_score:
            return "high"
        elif score >= min_score:
            return "medium"
        else:
            return "low"

    def analyze_api(self, url: str, headers: Dict[str, str] = None,
                   cookies: Dict[str, str] = None, url_params: Dict[str, str] = None,
                   response_content: str = "") -> APIAnalysisResult:
        """åˆ†æå•ä¸ªAPI

        Args:
            url: API URL
            headers: HTTPå¤´éƒ¨
            cookies: Cookieä¿¡æ¯
            url_params: URLå‚æ•°
            response_content: å“åº”å†…å®¹

        Returns:
            APIAnalysisResult: åˆ†æç»“æœ
        """
        result = APIAnalysisResult(url=url)

        # 1. è¯†åˆ«é‡‘èæœºæ„
        institution_name, institution_type, matched_domain = self.identify_institution(url)
        result.institution = institution_name
        result.institution_type = institution_type

        # 2. è®¡ç®—åŸºç¡€åˆ†æ•°
        scoring_weights = self.features_config.get("analysis_configuration", {}).get("scoring_weights", {})
        total_score = 0

        # åŸŸååŒ¹é…è®°å½•ï¼ˆä½†ä¸ç›´æ¥åŠ åˆ†ï¼‰
        domain_matched = False
        if institution_name:
            domain_matched = True
            result.matched_patterns.append(f"domain:{matched_domain}")

        # 3. APIæ¨¡å¼åŒ¹é…
        if institution_name:
            # æŸ¥æ‰¾æœºæ„æ•°æ®
            institution_data = None
            for category_key in ["hong_kong_banks", "us_european_banks", "china_mainland_banks",
                               "global_investment_banks", "brokerage_firms", "cryptocurrency_exchanges",
                               "payment_platforms", "insurance_companies", "fintech_companies"]:
                category_data = self.features_config.get(category_key, {})
                institutions = category_data.get("institutions", {})
                for inst_key, inst_data in institutions.items():
                    if inst_data.get("name") == institution_name:
                        institution_data = inst_data
                        break
                if institution_data:
                    break

            if institution_data:
                patterns, pattern_bonus = self.match_api_patterns(url, institution_data)
                result.matched_patterns.extend(patterns)

                # ä¸¥æ ¼åŒ¹é…ï¼šå¿…é¡»åŒæ—¶æ»¡è¶³åŸŸååŒ¹é… AND APIæ¨¡å¼åŒ¹é…
                if domain_matched and patterns:
                    domain_score = scoring_weights.get("domain_match", 30)
                    total_score += domain_score + pattern_bonus

        # 4. é€šç”¨æ¨¡å¼åŒ¹é…ï¼ˆåªæœ‰åœ¨åŸŸååŒ¹é…çš„æƒ…å†µä¸‹æ‰åŠ åˆ†ï¼‰
        universal_patterns, universal_bonus = self.match_universal_patterns(url)
        result.matched_patterns.extend(universal_patterns)

        # ä¸¥æ ¼åŒ¹é…ï¼šé€šç”¨æ¨¡å¼åªæœ‰åœ¨åŸŸååŒ¹é…æ—¶æ‰æœ‰æ•ˆ
        if domain_matched and universal_patterns:
            total_score += universal_bonus

        # 5. ä¸¥æ ¼é‡‘èå…³é”®å­—æ£€æŸ¥ï¼ˆæ–°å¢ï¼‰
        is_strict_match, strict_keywords, strict_bonus = self.check_strict_financial_keywords(url, response_content)
        if is_strict_match:
            result.matched_patterns.extend(strict_keywords)
            total_score += strict_bonus

        # 5. è®¤è¯æ£€æµ‹
        has_auth, auth_types = self.detect_authentication(headers, cookies, url_params)
        result.authentication_detected = has_auth
        if has_auth:
            auth_score = scoring_weights.get("authentication_present", 15)
            total_score += auth_score
            result.matched_patterns.extend(auth_types)

        # 6. å“åº”å†…å®¹åˆ†æ
        has_financial_data, financial_fields = self.analyze_response_content(response_content)
        result.response_contains_financial_data = has_financial_data
        if has_financial_data:
            content_score = scoring_weights.get("response_content_match", 20)
            total_score += content_score
            result.matched_patterns.extend(financial_fields)

        # 7. æœ€ç»ˆä¸¥æ ¼è¯„åˆ†ï¼šåªæœ‰æ»¡è¶³å¤šä¸ªæ¡ä»¶çš„APIæ‰èƒ½è·å¾—é«˜åˆ†
        final_score = 0

        # åŸºç¡€æ¡ä»¶ï¼šå¿…é¡»æœ‰åŸŸååŒ¹é…
        if domain_matched:
            # æ¡ä»¶1ï¼šæœ‰APIæ¨¡å¼åŒ¹é…æˆ–é€šç”¨æ¨¡å¼åŒ¹é…
            has_pattern_match = len([p for p in result.matched_patterns if not p.startswith("domain:")]) > 0

            # æ¡ä»¶2ï¼šæœ‰ä¸¥æ ¼å…³é”®å­—åŒ¹é…
            has_strict_match = is_strict_match

            # æ¡ä»¶3ï¼šæœ‰è®¤è¯ä¿¡æ¯
            has_auth = has_auth if 'has_auth' in locals() else False

            # æ¡ä»¶4ï¼šæœ‰é‡‘èæ•°æ®å†…å®¹
            has_financial_content = has_financial_data if 'has_financial_data' in locals() else False

            # ä¸¥æ ¼è¯„åˆ†é€»è¾‘
            if has_strict_match and has_pattern_match:
                final_score = total_score  # æ»¡è¶³ä¸¥æ ¼æ¡ä»¶ï¼Œç»™äºˆå®Œæ•´åˆ†æ•°
            elif has_strict_match or (has_pattern_match and len(result.matched_patterns) >= 3):
                final_score = int(total_score * 0.7)  # éƒ¨åˆ†æ»¡è¶³ï¼Œç»™äºˆ70%åˆ†æ•°
            elif has_pattern_match:
                final_score = int(total_score * 0.4)  # åªæœ‰æ¨¡å¼åŒ¹é…ï¼Œç»™äºˆ40%åˆ†æ•°
            else:
                final_score = 0  # ä¸æ»¡è¶³æ¡ä»¶ï¼Œä¸ç»™åˆ†

        result.value_score = final_score
        result.priority_level = self.calculate_priority_level(final_score)

        # 8. æ¨æ–­æ•°æ®ç±»å‹
        if "account" in url.lower() or "balance" in url.lower():
            result.data_types.append("account_data")
        if "transaction" in url.lower() or "history" in url.lower():
            result.data_types.append("transaction_data")
        if "investment" in url.lower() or "portfolio" in url.lower():
            result.data_types.append("investment_data")
        if "trading" in url.lower() or "order" in url.lower():
            result.data_types.append("trading_data")

        # ğŸ¯ é‰´æƒä¿¡æ¯æ£€æµ‹ï¼ˆä½œä¸ºè¯„åˆ†å› å­ï¼Œä¸æ˜¯é—¨æ§›ï¼‰
        has_auth_context = self.check_authentication_context(url, response_content, result)

        # ğŸ¯ APIåˆ†ç±»é€»è¾‘ï¼ˆç§»é™¤ç¡¬æ€§é‰´æƒé—¨æ§›ï¼‰
        result.api_category, result.provider_worthy = self.classify_api(url, result.matched_patterns)

        # ğŸ¯ åŸºäºé‰´æƒä¿¡æ¯è°ƒæ•´è¯„åˆ†
        if has_auth_context and result.api_category == "query":
            result.value_score += 10  # æœ‰é‰´æƒä¿¡æ¯çš„æŸ¥è¯¢APIåŠ åˆ†
        elif not has_auth_context and result.api_category == "query":
            result.value_score -= 5   # æ— é‰´æƒä¿¡æ¯çš„æŸ¥è¯¢APIå‡åˆ†ï¼Œä½†ä¸æ·˜æ±°

        result.analysis_details = {
            "domain_matched": bool(institution_name),
            "patterns_matched": len(result.matched_patterns),
            "auth_detected": has_auth,
            "financial_content": has_financial_data,
            "api_category": result.api_category,
            "provider_worthy": result.provider_worthy,
            "auth_context_detected": has_auth_context,  # ğŸ¯ é‰´æƒä¸Šä¸‹æ–‡æ£€æµ‹ï¼ˆè¯„åˆ†å› å­ï¼‰
            "scoring_breakdown": {
                "domain_score": scoring_weights.get("domain_match", 30) if institution_name else 0,
                "pattern_score": pattern_bonus if 'pattern_bonus' in locals() else universal_bonus,
                "auth_score": scoring_weights.get("authentication_present", 15) if has_auth else 0,
                "content_score": scoring_weights.get("response_content_match", 20) if has_financial_data else 0,
                "auth_context_bonus": 10 if has_auth_context and result.api_category == "query" else 0
            }
        }

        return result

    def classify_api(self, url: str, matched_patterns: List[str]) -> Tuple[str, bool]:
        """åˆ†ç±»APIç±»å‹ï¼Œåˆ¤æ–­æ˜¯å¦å€¼å¾—ç”Ÿæˆprovider

        Args:
            url: API URL
            matched_patterns: åŒ¹é…çš„æ¨¡å¼åˆ—è¡¨

        Returns:
            Tuple[str, bool]: (api_category, provider_worthy)
        """
        classification_config = self.features_config.get("analysis_configuration", {}).get("api_classification", {})

        provider_worthy_patterns = classification_config.get("provider_worthy_patterns", [])
        auth_only_patterns = classification_config.get("authentication_only_patterns", [])
        resource_patterns = classification_config.get("resource_patterns", [])

        url_lower = url.lower()

        # 1. ğŸ¯ é‡æ–°è®¾è®¡ï¼šåŒºåˆ†çœŸæ­£çš„è®¤è¯æ“ä½œå’Œè·¯å¾„è®¤è¯
        has_strong_auth_pattern = False
        has_weak_auth_pattern = False
        has_path_auth_only = False  # ä»…è·¯å¾„è®¤è¯ï¼ˆå¦‚/ibanking/ï¼‰

        for pattern in matched_patterns:
            # å¼ºè®¤è¯æ¨¡å¼ï¼šæ˜ç¡®çš„ç™»å½•æ“ä½œ
            if any(strong_auth in pattern for strong_auth in [
                'url:logon', 'content:login', 'content:logon', 'Logon',
                'url:login', 'url:auth', 'url:signin', 'content:auth', 'content:signin'
            ]):
                has_strong_auth_pattern = True
                break
            # ğŸ¯ åŒºåˆ†è·¯å¾„è®¤è¯å’ŒçœŸæ­£çš„è®¤è¯æ“ä½œ
            elif 'authentication_operations:path:' in pattern:
                has_path_auth_only = True
            # å…¶ä»–è®¤è¯æ¨¡å¼
            elif any(weak_auth in pattern for weak_auth in auth_only_patterns):
                has_weak_auth_pattern = True

        # 3. æ£€æŸ¥æ˜¯å¦åŒ…å«çœŸæ­£çš„æŸ¥è¯¢æ¨¡å¼ï¼ˆæ’é™¤é€šç”¨çš„accountå…³é”®å­—ï¼‰
        has_strong_query_pattern = False
        has_weak_query_pattern = False

        for pattern in matched_patterns:
            # å¼ºæŸ¥è¯¢æ¨¡å¼ï¼šæ˜ç¡®çš„æ•°æ®æŸ¥è¯¢
            if any(strong_query in pattern for strong_query in ['core_banking:', 'content:balance', 'content:overview', 'field:']):
                has_strong_query_pattern = True
                break
            # å¼±æŸ¥è¯¢æ¨¡å¼ï¼šå¯èƒ½çš„æŸ¥è¯¢ç›¸å…³ï¼ˆå¦‚é€šç”¨çš„accountï¼‰
            elif any(weak_query in pattern for weak_query in ['content:account', 'url:acc']):
                has_weak_query_pattern = True

        # 4. æ£€æŸ¥URLä¸­çš„æ˜ç¡®æŒ‡ç¤º
        auth_keywords = [
            'login', 'logon', 'auth', 'signin', 'sign-in',
            'lgn',  # ä¸­é“¶é¦™æ¸¯å¯èƒ½ä½¿ç”¨çš„ç¼©å†™
            'default',  # å¦‚ lgn.default.do
            'verify', 'validation',  # éªŒè¯ç›¸å…³
            'session', 'token'  # ä¼šè¯ç›¸å…³
        ]
        url_indicates_auth = any(auth_keyword in url_lower for auth_keyword in auth_keywords)

        query_keywords = [
            'overview', 'balance', 'account', 'detail', 'info',
            'acc.overview',  # ä¸­é“¶é¦™æ¸¯çš„è´¦æˆ·æ¦‚è§ˆ
            'transaction', 'history', 'statement'
        ]
        url_indicates_query = any(query_keyword in url_lower for query_keyword in query_keywords)

        # 5. ğŸ¯ é‡æ–°è®¾è®¡çš„æ™ºèƒ½åˆ†ç±»å†³ç­–ï¼ˆä¸šåŠ¡ä¼˜å…ˆï¼‰

        # ğŸ¯ æœ€é«˜ä¼˜å…ˆçº§ï¼šå¼ºæŸ¥è¯¢æ¨¡å¼ï¼ˆæ ¸å¿ƒä¸šåŠ¡APIï¼‰
        # å³ä½¿æœ‰è®¤è¯è·¯å¾„ï¼Œå¦‚æœæœ‰æ˜ç¡®çš„ä¸šåŠ¡æŸ¥è¯¢ç‰¹å¾ï¼Œä¼˜å…ˆåˆ†ç±»ä¸ºquery
        if has_strong_query_pattern:
            return "query", True

        # ğŸ¯ ç¬¬äºŒä¼˜å…ˆçº§ï¼šå¼±æŸ¥è¯¢æ¨¡å¼ + URLæŒ‡ç¤ºæŸ¥è¯¢
        # ä¸šåŠ¡APIä¼˜å…ˆäºè·¯å¾„è®¤è¯
        if has_weak_query_pattern and url_indicates_query:
            return "query", True

        # ğŸ¯ ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šå¼ºè®¤è¯æ¨¡å¼ï¼ˆæ˜ç¡®çš„ç™»å½•æ“ä½œï¼‰
        if has_strong_auth_pattern or url_indicates_auth:
            # è¿›ä¸€æ­¥åŒºåˆ†ç™»å½•é¡µé¢å’Œç™»å½•æäº¤
            if 'POST' in str(matched_patterns) or any('submit' in p.lower() for p in matched_patterns):
                return "auth", False  # ç™»å½•æäº¤ï¼Œä¸æ„å»ºproviderï¼Œä½†æœ‰ä¸Šä¸‹æ–‡ä»·å€¼
            else:
                return "auth", False  # ç™»å½•é¡µé¢ï¼Œä¸æ„å»ºproviderï¼Œä½†å¯ä½œä¸ºloginUrl

        # ğŸ¯ ç¬¬å››ä¼˜å…ˆçº§ï¼šå¼±æŸ¥è¯¢æ¨¡å¼ï¼ˆå³ä½¿åªæœ‰è·¯å¾„è®¤è¯ï¼‰
        # å¦‚æœæœ‰ä»»ä½•æŸ¥è¯¢ç‰¹å¾ï¼Œä¼˜å…ˆè€ƒè™‘ä¸ºä¸šåŠ¡API
        if has_weak_query_pattern:
            return "query", True

        # ğŸ¯ ç¬¬äº”ä¼˜å…ˆçº§ï¼šå¼±è®¤è¯æ¨¡å¼ä½†æ²¡æœ‰æŸ¥è¯¢æ¨¡å¼
        if has_weak_auth_pattern and not has_weak_query_pattern:
            return "auth", False

        # ğŸ¯ ç¬¬å…­ä¼˜å…ˆçº§ï¼šä»…è·¯å¾„è®¤è¯ï¼ˆå¦‚/ibanking/ï¼‰ä½†æ²¡æœ‰å…¶ä»–ç‰¹å¾
        if has_path_auth_only and not has_weak_query_pattern:
            return "auth", False

        # ğŸ¯ ç¬¬ä¸ƒä¼˜å…ˆçº§ï¼šæ£€æŸ¥æ˜¯å¦ä¸ºèµ„æºç±»API
        if self._is_resource_api(url_lower, resource_patterns):
            return "resource", False

        return "unknown", False

    def _is_resource_api(self, url_lower: str, resource_patterns: List[str]) -> bool:
        """æ›´ç²¾ç¡®çš„èµ„æºAPIæ£€æµ‹ï¼Œé¿å…è¯¯æ€è®¤è¯é¡µé¢"""

        # ğŸ¯ æ’é™¤æ˜æ˜¾çš„è®¤è¯é¡µé¢ï¼ˆå³ä½¿åŒ…å«èµ„æºå…³é”®å­—ï¼‰
        auth_indicators = ['/login/', '/logon/', '/signin/', '/auth/']
        if any(indicator in url_lower for indicator in auth_indicators):
            return False

        # ğŸ¯ æ›´ç²¾ç¡®çš„èµ„æºæ¨¡å¼åŒ¹é…
        for pattern in resource_patterns:
            if pattern == 'js':
                # åªåŒ¹é…çœŸæ­£çš„JSæ–‡ä»¶ï¼Œä¸åŒ¹é….jsp
                if url_lower.endswith('.js') or '/js/' in url_lower:
                    return True
            elif pattern == 'css':
                # åªåŒ¹é…çœŸæ­£çš„CSSæ–‡ä»¶
                if url_lower.endswith('.css') or '/css/' in url_lower:
                    return True
            else:
                # å…¶ä»–æ¨¡å¼ä¿æŒåŸæœ‰é€»è¾‘
                if pattern in url_lower:
                    return True

        return False

    def analyze_login_apis(self, all_flows: List[Dict]) -> Dict:
        """å®Œæ•´çš„ç™»å½•APIåˆ†æç®—æ³•ï¼ˆåœ¨æ¸…æ´—é˜¶æ®µæ‰§è¡Œï¼‰

        Args:
            all_flows: æ‰€æœ‰æµæ•°æ®

        Returns:
            Dict: ç™»å½•APIåˆ†æç»“æœ
        """
        print("ğŸ” å¼€å§‹å®Œæ•´çš„ç™»å½•APIåˆ†æ...")

        # ç¬¬ä¸€éƒ¨åˆ†ï¼šé€šè¿‡è¡Œä¸ºç‰¹å¾å‘ç°ç™»å½•æäº¤é¡µ
        login_submits = self._discover_login_submits_by_behavior(all_flows)
        print(f"ğŸ“¤ å‘ç° {len(login_submits)} ä¸ªç™»å½•æäº¤é¡µå€™é€‰")

        # ç¬¬äºŒéƒ¨åˆ†ï¼šé€šè¿‡å…³é”®å­—åŒ¹é…å‘ç°ç™»å½•é¡µé¢
        login_pages = self._discover_login_pages_by_keywords(all_flows)
        print(f"ğŸ  å‘ç° {len(login_pages)} ä¸ªç™»å½•é¡µé¢å€™é€‰")

        # ç¬¬ä¸‰éƒ¨åˆ†ï¼šå»ºç«‹å…³è”å…³ç³»å’Œç»¼åˆè¯„åˆ†
        login_pairs = self._match_login_pages_and_submits(login_pages, login_submits)
        print(f"ğŸ”— å»ºç«‹ {len(login_pairs)} ä¸ªç™»å½•é¡µé¢-æäº¤é¡µå…³è”")

        # ç¬¬å››éƒ¨åˆ†ï¼šä¸ºæ¯ä¸ªåŸŸåæ¨èæœ€ä½³ç™»å½•URL
        recommendations = self._recommend_login_urls(login_pairs, login_pages, login_submits)

        return {
            'login_submits': login_submits,
            'login_pages': login_pages,
            'login_pairs': login_pairs,
            'recommendations': recommendations
        }

    def _discover_login_submits_by_behavior(self, all_flows: List[Dict]) -> List[Dict]:
        """ç¬¬ä¸€éƒ¨åˆ†ï¼šé€šè¿‡è¡Œä¸ºç‰¹å¾å‘ç°ç™»å½•æäº¤é¡µ"""
        candidates = []

        for flow in all_flows:
            url = flow.get('url', '')
            method = flow.get('method', '').upper()
            request_body = flow.get('request_body', '')

            # å¿…é¡»æ˜¯POSTè¯·æ±‚
            if method != 'POST':
                continue

            if not request_body:
                continue

            # å¤„ç†bytesç±»å‹
            if isinstance(request_body, bytes):
                try:
                    request_body = request_body.decode('utf-8', errors='ignore')
                except:
                    request_body = str(request_body)

            request_body_lower = request_body.lower()

            # ğŸ¯ æ£€æµ‹è®¤è¯å­—æ®µ
            auth_indicators = [
                'loginid', 'userid', 'username', 'user', 'login',
                'password', 'passwd', 'pwd', 'pass',
                'vercode', 'captcha', 'verify'
            ]

            auth_field_count = sum(1 for indicator in auth_indicators if indicator in request_body_lower)

            # è‡³å°‘åŒ…å«2ä¸ªè®¤è¯ç›¸å…³å­—æ®µ
            if auth_field_count >= 2:
                score = self._score_login_submit_by_behavior(url, flow)
                candidates.append({
                    'url': url,
                    'type': 'submit',
                    'score': score,
                    'auth_field_count': auth_field_count,
                    'method': method,
                    'domain': self._extract_domain(url)
                })

        return candidates

    def _discover_login_pages_by_keywords(self, all_flows: List[Dict]) -> List[Dict]:
        """ç¬¬äºŒéƒ¨åˆ†ï¼šé€šè¿‡å…³é”®å­—åŒ¹é…å‘ç°ç™»å½•é¡µé¢"""
        candidates = []

        for flow in all_flows:
            url = flow.get('url', '')
            method = flow.get('method', '').upper()

            # é€šå¸¸æ˜¯GETè¯·æ±‚
            if method != 'GET':
                continue

            url_lower = url.lower()

            # ğŸ¯ æ‰©å±•ç™»å½•é¡µé¢å…³é”®å­—ï¼ŒåŒ…å«lgnç¼©å†™
            page_keywords = ['login', 'logon', 'signin', 'lgn']

            has_keyword = any(keyword in url_lower for keyword in page_keywords)
            if not has_keyword:
                continue

            # ğŸ¯ ä¿®æ”¹æ’é™¤é€»è¾‘ï¼šä¸æ’é™¤.jspæ–‡ä»¶ï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸æ˜¯çœŸæ­£çš„ç™»å½•é¡µé¢
            exclude_patterns = ['servlet', 'submit', 'authenticate', '.css', '.png', '.jpg', '.gif']
            # ç§»é™¤äº† '.js' é¿å…è¯¯æ€ .jsp æ–‡ä»¶
            if any(pattern in url_lower for pattern in exclude_patterns):
                continue

            score = self._score_login_page_by_keywords(url, flow)
            candidates.append({
                'url': url,
                'type': 'page',
                'score': score,
                'method': method,
                'domain': self._extract_domain(url)
            })

        return candidates

    def check_authentication_context(self, url: str, response_content: str, analysis_result) -> bool:
        """æ£€æŸ¥APIæ˜¯å¦å…·æœ‰é‰´æƒä¸Šä¸‹æ–‡ï¼ˆè¯„åˆ†å› å­ï¼Œä¸æ˜¯é—¨æ§›ï¼‰

        Args:
            url: API URL
            response_content: å“åº”å†…å®¹
            analysis_result: åˆ†æç»“æœå¯¹è±¡

        Returns:
            bool: æ˜¯å¦æ£€æµ‹åˆ°é‰´æƒä¸Šä¸‹æ–‡
        """
        auth_config = self.features_config.get("analysis_configuration", {}).get("api_classification", {}).get("authentication_indicators", {})

        if not auth_config:
            return False  # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œè¿”å›Falseï¼ˆä¸å½±å“å‡†å…¥ï¼‰

        url_auth_params = auth_config.get("url_auth_params", [])
        response_auth_fields = auth_config.get("response_auth_fields", [])

        url_lower = url.lower()

        # ğŸ¯ æ£€æŸ¥URLä¸­çš„é‰´æƒå‚æ•°
        for auth_param in url_auth_params:
            if auth_param.lower() in url_lower:
                return True

        # ğŸ¯ æ£€æŸ¥å“åº”å†…å®¹ä¸­çš„é‰´æƒå­—æ®µ
        if response_content:
            response_lower = response_content.lower()
            for auth_field in response_auth_fields:
                if auth_field.lower() in response_lower:
                    return True

        # ğŸ¯ ä¸å†è¿›è¡Œæ¨å®šï¼Œåªæ£€æµ‹æ˜ç¡®çš„é‰´æƒä¿¡æ¯
        return False

    def _score_login_submit_by_behavior(self, url: str, flow: Dict) -> int:
        """ä¸ºç™»å½•æäº¤é¡µè¯„åˆ†ï¼ˆè¡Œä¸ºç‰¹å¾ï¼‰"""
        score = 0
        url_lower = url.lower()

        # URLå…³é”®å­—è¯„åˆ†
        submit_keywords = ['login', 'logon', 'authenticate', 'signin', 'submit', 'default']
        for keyword in submit_keywords:
            if keyword in url_lower:
                score += 10
                break

        # POSTæ–¹æ³•åŸºç¡€åˆ†
        score += 15

        # è¯·æ±‚ä½“è®¤è¯å­—æ®µè¯„åˆ†
        request_body = flow.get('request_body', '')
        if request_body:
            if isinstance(request_body, bytes):
                try:
                    request_body = request_body.decode('utf-8', errors='ignore')
                except:
                    request_body = str(request_body)

            auth_fields = ['username', 'password', 'userid', 'pwd', 'loginid']
            for field in auth_fields:
                if field in request_body.lower():
                    score += 20
                    break

        # å“åº”ç‰¹å¾è¯„åˆ†
        response_headers = flow.get('response_headers', {})
        set_cookie = response_headers.get('Set-Cookie', '')
        if set_cookie and any(keyword in str(set_cookie).lower() for keyword in ['session', 'jsessionid', 'token']):
            score += 15

        status_code = flow.get('status_code', 0)
        if status_code in [302, 301]:
            score += 10
        elif status_code == 200:
            score += 5

        return score

    def _score_login_page_by_keywords(self, url: str, flow: Dict) -> int:
        """ä¸ºç™»å½•é¡µé¢è¯„åˆ†ï¼ˆå…³é”®å­—åŒ¹é…ï¼‰"""
        score = 0
        url_lower = url.lower()

        # ğŸ¯ URLå…³é”®å­—è¯„åˆ†ï¼ˆå¢åŠ lgnæ”¯æŒï¼‰
        if 'lgn' in url_lower and ('index' in url_lower or '.jsp' in url_lower):
            score += 20  # lgn + å…·ä½“é¡µé¢æ–‡ä»¶ï¼Œå¾ˆå¯èƒ½æ˜¯çœŸæ­£çš„ç™»å½•é¡µ
        elif 'login' in url_lower:
            score += 15
        elif 'logon' in url_lower:
            score += 12
        elif 'signin' in url_lower:
            score += 10

        # ğŸ¯ æ–‡ä»¶ç±»å‹è¯„åˆ†ï¼ˆæé«˜å…·ä½“é¡µé¢æ–‡ä»¶çš„åˆ†æ•°ï¼‰
        if url_lower.endswith('.jsp'):
            score += 15  # JSPé¡µé¢é€šå¸¸æ˜¯å…·ä½“çš„åŠŸèƒ½é¡µé¢
        elif any(ext in url_lower for ext in ['.html', '.htm', '.php']):
            score += 12
        elif url_lower.endswith('/login') or url_lower.endswith('/logon'):
            score += 8  # ç®€å•è·¯å¾„åˆ†æ•°é™ä½

        # ğŸ¯ è·¯å¾„æ·±åº¦è¯„åˆ†ï¼ˆæ›´æ·±çš„è·¯å¾„å¯èƒ½æ›´å…·ä½“ï¼‰
        path_depth = url.count('/') - 2  # å‡å»åè®®éƒ¨åˆ†
        if path_depth >= 2:
            score += 5  # æ·±å±‚è·¯å¾„åŠ åˆ†

        # ğŸ¯ å…·ä½“æ€§è¯„åˆ†
        if any(keyword in url_lower for keyword in ['index', 'main', 'form']):
            score += 8  # åŒ…å«å…·ä½“åŠŸèƒ½å…³é”®å­—

        # GETæ–¹æ³•åŸºç¡€åˆ†
        score += 5

        # å“åº”çŠ¶æ€è¯„åˆ†
        status_code = flow.get('status_code', 0)
        if status_code == 200:
            score += 5

        return score

    def _match_login_pages_and_submits(self, login_pages: List[Dict], login_submits: List[Dict]) -> List[Dict]:
        """ç¬¬ä¸‰éƒ¨åˆ†ï¼šå»ºç«‹ç™»å½•é¡µé¢å’Œæäº¤é¡µçš„å…³è”å…³ç³»"""
        pairs = []

        for submit in login_submits:
            submit_domain = submit['domain']
            submit_url = submit['url']

            # å¯»æ‰¾åŒåŸŸåçš„ç™»å½•é¡µé¢
            domain_pages = [page for page in login_pages if page['domain'] == submit_domain]

            if domain_pages:
                # ğŸ¯ è®¡ç®—URLç›¸ä¼¼åº¦ï¼Œé€‰æ‹©æœ€åŒ¹é…çš„é¡µé¢ï¼ˆä¼˜å…ˆè€ƒè™‘è·ç¦»ï¼‰
                best_page = None
                best_similarity = 0
                best_combined_score = 0

                for page in domain_pages:
                    similarity = self._calculate_url_similarity(submit_url, page['url'])
                    # ğŸ¯ ç»¼åˆè€ƒè™‘ç›¸ä¼¼åº¦å’Œé¡µé¢è¯„åˆ†ï¼Œä½†ç›¸ä¼¼åº¦æƒé‡æ›´é«˜
                    combined_score = similarity * 2 + page['score'] * 0.5

                    if combined_score > best_combined_score:
                        best_combined_score = combined_score
                        best_similarity = similarity
                        best_page = page

                if best_page:
                    # ç»¼åˆè¯„åˆ†ï¼šæäº¤é¡µè¯„åˆ† + é¡µé¢è¯„åˆ† + ç›¸ä¼¼åº¦
                    combined_score = submit['score'] + best_page['score'] + best_similarity

                    pairs.append({
                        'domain': submit_domain,
                        'login_page': best_page,
                        'login_submit': submit,
                        'similarity': best_similarity,
                        'combined_score': combined_score
                    })

        return pairs

    def _recommend_login_urls(self, login_pairs: List[Dict], login_pages: List[Dict], login_submits: List[Dict]) -> Dict:
        """ç¬¬å››éƒ¨åˆ†ï¼šä¸ºæ¯ä¸ªåŸŸåæ¨èæœ€ä½³ç™»å½•URL"""
        recommendations = {}

        # æŒ‰åŸŸååˆ†ç»„
        domains = set()
        for item in login_pairs + login_pages + login_submits:
            domains.add(item['domain'])

        for domain in domains:
            domain_pairs = [pair for pair in login_pairs if pair['domain'] == domain]
            domain_pages = [page for page in login_pages if page['domain'] == domain]
            domain_submits = [submit for submit in login_submits if submit['domain'] == domain]

            best_url = None
            best_score = 0
            recommendation_type = 'none'

            # ä¼˜å…ˆé€‰æ‹©æœ‰é…å¯¹çš„ç™»å½•é¡µé¢
            if domain_pairs:
                best_pair = max(domain_pairs, key=lambda x: x['combined_score'])
                best_url = best_pair['login_page']['url']
                best_score = best_pair['combined_score']
                recommendation_type = 'paired_page'

            # å…¶æ¬¡é€‰æ‹©ç‹¬ç«‹çš„ç™»å½•é¡µé¢
            elif domain_pages:
                best_page = max(domain_pages, key=lambda x: x['score'])
                best_url = best_page['url']
                best_score = best_page['score']
                recommendation_type = 'standalone_page'

            # æœ€åé€‰æ‹©ç™»å½•æäº¤é¡µï¼ˆå»æ‰å‚æ•°ï¼‰
            elif domain_submits:
                best_submit = max(domain_submits, key=lambda x: x['score'])
                best_url = best_submit['url'].split('?')[0]
                best_score = best_submit['score']
                recommendation_type = 'submit_fallback'

            if best_url:
                recommendations[domain] = {
                    'login_url': best_url,
                    'score': best_score,
                    'type': recommendation_type,
                    'confidence': min(best_score / 100.0, 1.0)  # è½¬æ¢ä¸º0-1çš„ç½®ä¿¡åº¦
                }

        return recommendations

    def _extract_domain(self, url: str) -> str:
        """æå–åŸŸå"""
        from urllib.parse import urlparse
        return urlparse(url).netloc

    def _calculate_url_similarity(self, url1: str, url2: str) -> int:
        """è®¡ç®—URLç›¸ä¼¼åº¦è¯„åˆ†"""
        from urllib.parse import urlparse

        parsed1 = urlparse(url1)
        parsed2 = urlparse(url2)

        score = 0

        # è·¯å¾„ç›¸ä¼¼åº¦
        path1_parts = parsed1.path.strip('/').split('/')
        path2_parts = parsed2.path.strip('/').split('/')

        common_parts = set(path1_parts) & set(path2_parts)
        if common_parts:
            score += len(common_parts) * 3

        # è·¯å¾„é•¿åº¦ç›¸ä¼¼
        if abs(len(path1_parts) - len(path2_parts)) <= 1:
            score += 5

        return score


def main():
    """å‘½ä»¤è¡Œæµ‹è¯•æ¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description='é‡‘èAPIç‰¹å¾åˆ†æå™¨æµ‹è¯•')
    parser.add_argument('--test-url', '-u', help='æµ‹è¯•å•ä¸ªURL')
    parser.add_argument('--config', '-c', help='ç‰¹å¾é…ç½®æ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # åˆ›å»ºåˆ†æå™¨
    analyzer = FinancialAPIAnalyzer(args.config)

    if args.test_url:
        # æµ‹è¯•å•ä¸ªURL
        result = analyzer.analyze_api(args.test_url)
        print(f"URL: {args.test_url}")
        print(f"æœºæ„: {result.institution} ({result.institution_type})")
        print(f"ä»·å€¼è¯„åˆ†: {result.value_score}")
        print(f"ä¼˜å…ˆçº§: {result.priority_level}")
        print(f"åŒ¹é…æ¨¡å¼: {result.matched_patterns}")
        print(f"æ•°æ®ç±»å‹: {result.data_types}")
        print(f"è®¤è¯æ£€æµ‹: {result.authentication_detected}")
    else:
        # æµ‹è¯•ç¤ºä¾‹URLåˆ—è¡¨
        test_urls = [
            "https://its.bochk.com/acc.overview.do",
            "https://www.cmbwinglungbank.com/ibanking/McpCSReqServlet",
            "https://api.binance.com/api/v3/account",
            "https://chase.com/api/authentication/login",
            "https://www.hsbc.com.hk/css/styles.css"
        ]

        print("ğŸ” é‡‘èAPIç‰¹å¾åˆ†ææµ‹è¯•")
        print("=" * 50)

        for url in test_urls:
            result = analyzer.analyze_api(url)
            print(f"\nURL: {url}")
            print(f"æœºæ„: {result.institution or 'æœªè¯†åˆ«'} ({result.institution_type or 'N/A'})")
            print(f"è¯„åˆ†: {result.value_score} | ä¼˜å…ˆçº§: {result.priority_level}")
            print(f"åŒ¹é…: {len(result.matched_patterns)}ä¸ªæ¨¡å¼")


if __name__ == "__main__":
    main()
