#!/usr/bin/env python3
"""
ç‹¬ç«‹çš„é“¶è¡ŒProviderç”ŸæˆAPIæœåŠ¡å™¨
å®Œå…¨ç‹¬ç«‹äºmitmproxyï¼Œæä¾›REST APIæ¥å£æ¥è¿è¡Œä¸»æµç¨‹

åŠŸèƒ½ï¼š
1. å¼‚æ­¥æ‰§è¡Œä¸»æµç¨‹
2. å®æ—¶çŠ¶æ€è·Ÿè¸ª
3. æ–‡ä»¶ä¸Šä¼ å’Œç®¡ç†
4. ç»“æœæŸ¥è¯¢å’Œä¸‹è½½
5. é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

APIç«¯ç‚¹ï¼š
- GET /status - æŸ¥è¯¢å½“å‰çŠ¶æ€
- POST /reset - é‡ç½®çŠ¶æ€
- POST /trigger - è§¦å‘ä¸»æµç¨‹ï¼ˆåœ¨çº¿æ¨¡å¼ï¼‰
- POST /upload-and-trigger - ä¸Šä¼ mitmæ–‡ä»¶å¹¶è§¦å‘æµç¨‹ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰
- GET /providers - è·å–æœ€æ–°çš„Provideråˆ—è¡¨
- GET /results/{file_id} - ä¸‹è½½ç»“æœæ–‡ä»¶
- GET /files - åˆ—å‡ºæ‰€æœ‰è¾“å‡ºæ–‡ä»¶
- GET /health - å¥åº·æ£€æŸ¥
"""

import os
import json
import asyncio
import uuid
import time
import shutil
import socket
import subprocess
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path
import logging

from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks
from http import HTTPStatus
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import uvicorn

# å¯¼å…¥ä¸»æµç¨‹ç›¸å…³æ¨¡å—
from integrated_main_pipeline import IntegratedMainPipeline
from dynamic_config import dynamic_config



# ç¡®ä¿logsç›®å½•å­˜åœ¨
os.makedirs('logs', exist_ok=True)

# é…ç½®æ—¥å¿— - æ‰€æœ‰æ—¥å¿—æ–‡ä»¶å†™å…¥logsç›®å½•
from datetime import datetime
log_filename = f'logs/api_server_{datetime.now().strftime("%Y%m%d")}.log'

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# è·å–çœŸå®çš„mitmé…ç½®ç”¨äºAPIæ–‡æ¡£æ˜¾ç¤º
def get_real_mitm_config():
    """è·å–çœŸå®çš„mitmé…ç½®ï¼Œç”¨äºAPIæ–‡æ¡£é»˜è®¤å€¼"""
    try:
        dynamic_config.discover_running_mitmproxy()
        real_host = dynamic_config.get_mitm_host()
        real_port = dynamic_config.get_mitm_port()
        return real_host, real_port
    except Exception:
        return "127.0.0.1", 8080  # fallbacké»˜è®¤å€¼

# è·å–çœŸå®é…ç½®
REAL_MITM_HOST, REAL_MITM_PORT = get_real_mitm_config()

# Pydanticæ¨¡å‹
class TriggerRequest(BaseModel):
    mitm_host: Optional[str] = Field(
        default=REAL_MITM_HOST,
        description="mitmproxyä¸»æœºåœ°å€ï¼ˆè‡ªåŠ¨å‘ç°çš„çœŸå®åœ°å€ï¼‰",
        example=REAL_MITM_HOST
    )
    mitm_port: Optional[int] = Field(
        default=REAL_MITM_PORT,
        description="mitmproxyç«¯å£ï¼ˆè‡ªåŠ¨å‘ç°çš„çœŸå®ç«¯å£ï¼‰",
        example=REAL_MITM_PORT
    )
    output_dir: Optional[str] = Field(
        default="data",
        description="è¾“å‡ºç›®å½•",
        example="data"
    )

    def __init__(self, **data):
        super().__init__(**data)
        # è‡ªåŠ¨å‘ç°å¹¶å¡«å……çœŸå®çš„mitmé…ç½®
        try:
            dynamic_config.discover_running_mitmproxy()
            self.mitm_host = dynamic_config.get_mitm_host()
            self.mitm_port = dynamic_config.get_mitm_port()
            logger.info(f"ğŸ”„ è‡ªåŠ¨å¡«å……çœŸå®mitmé…ç½®: {self.mitm_host}:{self.mitm_port}")
        except Exception as e:
            logger.warning(f"âš ï¸  æ— æ³•è‡ªåŠ¨å¡«å……mitmé…ç½®: {e}")
            # ä¿æŒåŸæœ‰å€¼


class OfflineTriggerRequest(BaseModel):
    input_file: str  # å¿…éœ€ï¼šç¦»çº¿æ¨¡å¼ä¸‹çš„è¾“å…¥æ–‡ä»¶è·¯å¾„
    output_dir: Optional[str] = "data"

    def __init__(self, **data):
        # å¦‚æœæ²¡æœ‰æä¾›mitmé…ç½®ï¼Œåœ¨è¿è¡Œæ—¶ä½¿ç”¨åŠ¨æ€é…ç½®
        if 'mitm_host' not in data or data['mitm_host'] is None:
            data['mitm_host'] = dynamic_config.get_mitm_host()
        if 'mitm_port' not in data or data['mitm_port'] is None:
            data['mitm_port'] = dynamic_config.get_mitm_port()
        super().__init__(**data)

class StatusResponse(BaseModel):
    success: bool
    data: Dict[str, Any]
    message: str = ""

class APIResponse(BaseModel):
    success: bool
    message: str
    data: Dict[str, Any] = {}


# å…¨å±€çŠ¶æ€ç®¡ç†
class ServerState:
    def __init__(self):
        self.reset()

    def reset(self):
        self.status = "idle"  # idle, running, completed, error
        self.progress = 0
        self.message = "æœåŠ¡å™¨å·²å°±ç»ª"
        self.current_task_id = None
        self.start_time = None
        self.end_time = None
        self.result_files = []
        self.errors = []
        self.pipeline_result = None
        self.running_config = {}

# å…¨å±€çŠ¶æ€å®ä¾‹
server_state = ServerState()


# FastAPIåº”ç”¨
app = FastAPI(
    title="é“¶è¡ŒProviderç”ŸæˆAPIæœåŠ¡",
    description="ç‹¬ç«‹çš„é“¶è¡ŒProviderç”ŸæˆæœåŠ¡ï¼Œä»mitmproxyæŠ“åŒ…æ–‡ä»¶ç”ŸæˆReclaimåè®®æ ‡å‡†é…ç½®",
    version="1.0.0"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ç¡®ä¿å¿…è¦ç›®å½•å­˜åœ¨
def ensure_directories():
    """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
    dirs = ["data", "temp", "uploads"]
    for dir_name in dirs:
        os.makedirs(dir_name, exist_ok=True)
        logger.info(f"ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_name}")

ensure_directories()



def sort_providers_by_time(providers_array: List[Dict], reverse: bool = True) -> List[Dict]:
    """ç»Ÿä¸€çš„Provideræ’åºå‡½æ•°

    Args:
        providers_array: Provideræ•°ç»„
        reverse: Trueä¸ºå€’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰ï¼ŒFalseä¸ºæ­£åº

    Returns:
        æ’åºåçš„Provideræ•°ç»„
    """
    def get_provider_timestamp(provider):
        try:
            # ä»metadataä¸­è·å–ç”Ÿæˆæ—¶é—´
            generated_at = provider.get('providerConfig', {}).get('providerConfig', {}).get('metadata', {}).get('generated_at', '')
            if generated_at:
                # è§£æISOæ ¼å¼æ—¶é—´æˆ³
                from datetime import datetime
                return datetime.fromisoformat(generated_at.replace('Z', '+00:00'))
            else:
                # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                return datetime.now()
        except:
            # è§£æå¤±è´¥æ—¶ä½¿ç”¨å½“å‰æ—¶é—´
            return datetime.now()

    # æŒ‰æ—¶é—´æ’åº
    return sorted(providers_array, key=get_provider_timestamp, reverse=reverse)


def get_local_ip() -> str:
    """åŠ¨æ€è·å–æœ¬æœºIPåœ°å€"""
    try:
        # æ–¹æ³•1: è¿æ¥åˆ°è¿œç¨‹åœ°å€è·å–æœ¬åœ°IP
        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
            s.connect(("8.8.8.8", 80))
            return s.getsockname()[0]
    except Exception:
        pass

    try:
        # æ–¹æ³•2: é€šè¿‡ifconfigè·å–æ´»è·ƒç½‘ç»œæ¥å£çš„IP
        result = subprocess.run(
            ["ifconfig"],
            capture_output=True,
            text=True,
            timeout=5
        )
        if result.returncode == 0:
            lines = result.stdout.split('\n')
            for line in lines:
                if 'inet ' in line and '127.0.0.1' not in line and 'broadcast' in line:
                    parts = line.strip().split()
                    for i, part in enumerate(parts):
                        if part == "inet" and i + 1 < len(parts):
                            ip = parts[i + 1]
                            # ä¼˜å…ˆè¿”å›192.168.x.xæˆ–10.x.x.xçš„å†…ç½‘IP
                            if ip.startswith(('192.168.', '10.', '172.')):
                                return ip
    except Exception:
        pass

    try:
        # æ–¹æ³•3: é€šè¿‡hostnameè·å–
        hostname = socket.gethostname()
        return socket.gethostbyname(hostname)
    except Exception:
        pass

    # å¤‡ç”¨æ–¹æ¡ˆ: è¿”å›localhost
    return "127.0.0.1"


async def run_pipeline_async(config: Dict[str, Any], offline_mode: bool = False, input_file: str = None):
    """å¼‚æ­¥è¿è¡Œä¸»æµç¨‹"""
    global server_state

    task_id = str(uuid.uuid4())
    server_state.current_task_id = task_id
    server_state.status = "running"
    server_state.progress = 0
    server_state.message = "æ­£åœ¨åˆå§‹åŒ–ä¸»æµç¨‹..."
    server_state.start_time = datetime.now()
    server_state.running_config = config
    server_state.errors = []

    logger.info(f"å¼€å§‹æ‰§è¡Œä¸»æµç¨‹ä»»åŠ¡: {task_id}")
    logger.info(f"é…ç½®: {config}")
    logger.info(f"ç¦»çº¿æ¨¡å¼: {offline_mode}, è¾“å…¥æ–‡ä»¶: {input_file}")

    try:
        # æ›´æ–°è¿›åº¦ï¼šåˆå§‹åŒ–
        server_state.progress = 10
        server_state.message = "åˆ›å»ºé›†æˆä¸»æµç¨‹ç®¡é“å™¨..."

        # åˆ›å»ºé›†æˆä¸»æµç¨‹å®ä¾‹
        pipeline = IntegratedMainPipeline(config)

        # æ›´æ–°è¿›åº¦ï¼šå¼€å§‹æ‰§è¡Œ
        server_state.progress = 20
        server_state.message = "å¼€å§‹æ‰§è¡Œé›†æˆä¸»æµç¨‹..."

        # æ‰§è¡Œé›†æˆä¸»æµç¨‹
        result = pipeline.run_full_pipeline(
            offline_mode=offline_mode,
            input_file=input_file
        )

        # æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰æ•ˆ
        if result is None:
            raise Exception("é›†æˆä¸»æµç¨‹è¿”å›äº†ç©ºç»“æœ")

        # æ›´æ–°æœ€ç»ˆçŠ¶æ€
        if result.get('success', False):
            server_state.status = "completed"
            server_state.progress = 100

            # è·å–é›†æˆä¸»æµç¨‹çš„ç»“æœ
            report = result.get('report', {})

            # è·å–providerè®¡æ•° - é€‚é…æ–°çš„é›†æˆä¸»æµç¨‹ç»“æ„
            provider_results = report.get('provider_results', {})
            analysis_results = report.get('analysis_results', {})

            providers_count = provider_results.get('providers_count', 0)
            questionable_count = provider_results.get('questionable_count', 0)
            valuable_apis = analysis_results.get('valuable_apis', 0)

            server_state.message = f"é›†æˆä¸»æµç¨‹æ‰§è¡ŒæˆåŠŸï¼è¯†åˆ« {valuable_apis} ä¸ªæœ‰ä»·å€¼APIï¼ŒæˆåŠŸæ„å»º {providers_count} ä¸ªReclaim Providerï¼Œ{questionable_count} ä¸ªå­˜ç–‘API"
            server_state.pipeline_result = result

            # è®°å½•è¾“å‡ºæ–‡ä»¶ - é€‚é…é›†æˆä¸»æµç¨‹çš„ç»“æ„
            server_state.result_files = []

            # ä»é›†æˆä¸»æµç¨‹çš„output_filesç»“æ„è·å–æ–‡ä»¶åˆ—è¡¨
            output_files = result.get('output_files', {})
            if isinstance(output_files, dict):
                for file_path in output_files.values():
                    if file_path and os.path.exists(file_path):
                        server_state.result_files.append(file_path)

            # æ£€æŸ¥dataç›®å½•ä¸­çš„ç›¸å…³æ–‡ä»¶
            data_dir = config.get('output_dir', 'data')
            if os.path.exists(data_dir):
                for file in os.listdir(data_dir):
                    if file.endswith('.json') and any(prefix in file for prefix in
                        ['reclaim_providers_', 'questionable_apis_', 'feature_analysis_', 'integrated_pipeline_report_']):
                        file_path = os.path.join(data_dir, file)
                        if file_path not in server_state.result_files:
                            server_state.result_files.append(file_path)

            logger.info(f"é›†æˆä¸»æµç¨‹æ‰§è¡ŒæˆåŠŸ: {result}")
        else:
            server_state.status = "error"
            error_message = result.get('message', 'æœªçŸ¥é”™è¯¯') if result else 'é›†æˆä¸»æµç¨‹è¿”å›ç©ºç»“æœ'
            server_state.message = f"é›†æˆä¸»æµç¨‹æ‰§è¡Œå¤±è´¥: {error_message}"
            server_state.errors.append(error_message)
            logger.error(f"é›†æˆä¸»æµç¨‹æ‰§è¡Œå¤±è´¥: {result}")

    except Exception as e:
        server_state.status = "error"
        server_state.message = f"é›†æˆä¸»æµç¨‹æ‰§è¡Œå¼‚å¸¸: {str(e)}"
        server_state.errors.append(str(e))
        logger.error(f"é›†æˆä¸»æµç¨‹æ‰§è¡Œå¼‚å¸¸: {e}", exc_info=True)

    finally:
        server_state.end_time = datetime.now()
        if server_state.start_time:
            duration = server_state.end_time - server_state.start_time
            logger.info(f"ä»»åŠ¡ {task_id} å®Œæˆï¼Œè€—æ—¶: {duration}")


@app.get("/", response_class=JSONResponse)
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›APIä¿¡æ¯"""
    return {
        "service": "é“¶è¡ŒProviderç”ŸæˆAPIæœåŠ¡",
        "version": "1.0.0",
        "status": "running",
        "endpoints": {
            "health": "/health",
            "status": "/status",
            "reset": "/reset",
            "trigger": "/trigger",
            "upload": "/upload-and-trigger",
            "providers": "/providers",
            "files": "/files"
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "server_status": server_state.status
    }


@app.get("/status", response_model=StatusResponse)
async def get_status():
    """è·å–å½“å‰çŠ¶æ€"""
    global server_state

    # è®¡ç®—è¿è¡Œæ—¶é—´
    duration_seconds = None
    if server_state.start_time:
        if server_state.end_time:
            duration = server_state.end_time - server_state.start_time
        else:
            duration = datetime.now() - server_state.start_time
        duration_seconds = int(duration.total_seconds())

    status_data = {
        "status": server_state.status,
        "progress": server_state.progress,
        "message": server_state.message,
        "task_id": server_state.current_task_id,
        "start_time": server_state.start_time.isoformat() if server_state.start_time else None,
        "end_time": server_state.end_time.isoformat() if server_state.end_time else None,
        "duration_seconds": duration_seconds,
        "result_files_count": len(server_state.result_files),
        "errors": server_state.errors,
        "config": server_state.running_config
    }

    return StatusResponse(
        success=True,
        data=status_data,
        message="çŠ¶æ€æŸ¥è¯¢æˆåŠŸ"
    )


@app.post("/reset")
async def reset_status():
    """é‡ç½®æœåŠ¡å™¨çŠ¶æ€"""
    global server_state

    # å¦‚æœå½“å‰æœ‰ä»»åŠ¡åœ¨è¿è¡Œï¼Œä¸å…è®¸é‡ç½®
    if server_state.status == "running":
        raise HTTPException(
            status_code=400,
            detail="å½“å‰æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œæ— æ³•é‡ç½®çŠ¶æ€"
        )

    server_state.reset()
    logger.info("æœåŠ¡å™¨çŠ¶æ€å·²é‡ç½®")

    return APIResponse(
        success=True,
        message="æœåŠ¡å™¨çŠ¶æ€å·²é‡ç½®",
        data={"status": server_state.status}
    )


@app.post("/trigger")
async def trigger_pipeline(request: TriggerRequest):
    """è§¦å‘é›†æˆä¸»æµç¨‹ï¼ˆåœ¨çº¿æ¨¡å¼ï¼‰- ä»mitmproxyå¯¼å‡ºæ•°æ®å¹¶æ‰§è¡Œå®Œæ•´æµç¨‹"""
    global server_state

    # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œ
    if server_state.status == "running":
        raise HTTPException(
            status_code=400,
            detail="å·²æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œè¯·ç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆæˆ–é‡ç½®çŠ¶æ€"
        )

    # å§‹ç»ˆè‡ªåŠ¨å‘ç°çœŸå®çš„mitmä»£ç†é…ç½®ï¼ˆå¿½ç•¥ç”¨æˆ·è¾“å…¥çš„å‚æ•°ï¼‰
    try:
        logger.info("ğŸ” å¼€å§‹è‡ªåŠ¨å‘ç°çœŸå®è¿è¡Œçš„mitmä»£ç†...")

        # å¼ºåˆ¶é‡æ–°å‘ç°mitmä»£ç†
        dynamic_config.discover_running_mitmproxy()

        # è·å–å‘ç°çš„é…ç½®
        discovered_host = dynamic_config.get_mitm_host()
        discovered_port = dynamic_config.get_mitm_port()

        logger.info(f"âœ… è‡ªåŠ¨å‘ç°çœŸå®mitmä»£ç†: {discovered_host}:{discovered_port}")
        logger.info(f"ğŸ“ ç”¨æˆ·æä¾›çš„å‚æ•° {request.mitm_host}:{request.mitm_port} å·²è¢«è‡ªåŠ¨å‘ç°çš„é…ç½®è¦†ç›–")

        mitm_host = discovered_host
        mitm_port = discovered_port

    except Exception as e:
        logger.error(f"âŒ è‡ªåŠ¨å‘ç°å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ— æ³•å‘ç°è¿è¡Œä¸­çš„mitmä»£ç†: {str(e)}")

    config = {
        'mitm_host': mitm_host,
        'mitm_port': mitm_port,
        'output_dir': request.output_dir or 'data'
    }

    logger.info(f"å¼€å§‹åŒæ­¥æ‰§è¡Œé›†æˆä¸»æµç¨‹ä»»åŠ¡ï¼ˆåœ¨çº¿æ¨¡å¼ï¼‰ï¼Œé…ç½®: {config}")

    # åŒæ­¥æ‰§è¡Œé›†æˆä¸»æµç¨‹ - å¼ºåˆ¶ä½¿ç”¨åœ¨çº¿æ¨¡å¼
    await run_pipeline_async(config, offline_mode=False, input_file=None)

    # æ£€æŸ¥æ‰§è¡Œç»“æœ
    if server_state.status == "completed" and server_state.pipeline_result:
        result = server_state.pipeline_result

        # è¯»å–ç”Ÿæˆçš„provideræ•°æ®ï¼Œç›´æ¥è¿”å›ç»™å‰ç«¯
        providers_response = {
            "success": True,
            "message": server_state.message,
            "providers": []
        }

        try:
            # é€‚é…é›†æˆä¸»æµç¨‹çš„ç»“æœç»“æ„
            output_files = result.get('output_files', {})

            # è¯»å–Reclaim providersæ•°æ®
            providers_file = output_files.get('providers')
            if providers_file and os.path.exists(providers_file):
                with open(providers_file, 'r', encoding='utf-8') as f:
                    providers_data = json.load(f)
                    # ç›´æ¥è¿”å›providersåˆ—è¡¨
                    if isinstance(providers_data, dict) and 'providers' in providers_data:
                        raw_providers = providers_data['providers']
                        providers_response['metadata'] = providers_data.get('metadata', {})
                    elif isinstance(providers_data, list):
                        raw_providers = providers_data
                    else:
                        raw_providers = []

                    # ä½¿ç”¨ç»Ÿä¸€æ’åºå‡½æ•°è¿›è¡Œå€’åºæ’åº
                    providers_response['providers'] = sort_providers_by_time(raw_providers, reverse=True)

                    logger.info(f"å·²è¯»å–å¹¶æ’åº {len(providers_response['providers'])} ä¸ª Reclaim providersï¼ˆæŒ‰æ—¶é—´å€’åºï¼‰")

        except Exception as e:
            logger.warning(f"è¯»å–provideræ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
            providers_response['message'] = f"ä¸»æµç¨‹æ‰§è¡ŒæˆåŠŸï¼Œä½†è¯»å–provideræ•°æ®å¤±è´¥: {str(e)}"

        logger.info(f"ä¸»æµç¨‹åŒæ­¥æ‰§è¡Œå®Œæˆï¼Œè¿”å› {len(providers_response['providers'])} ä¸ªproviders")

        # æ·»åŠ çœŸå®è¯†åˆ«åˆ°çš„mitmé…ç½®ä¿¡æ¯åˆ°å“åº”ä¸­
        enhanced_response = {
            "mitm_host": mitm_host,  # çœŸå®è¯†åˆ«åˆ°çš„host
            "mitm_port": mitm_port,  # çœŸå®è¯†åˆ«åˆ°çš„port
            "providers": providers_response['providers'],
            "metadata": providers_response['metadata'],
            "message": providers_response['message']
        }

        return APIResponse(
            success=True,
            message=providers_response['message'],
            data=enhanced_response
        )
    else:
        # æ‰§è¡Œå¤±è´¥
        error_msg = server_state.message if server_state.status == "error" else "æ‰§è¡Œæœªå®Œæˆ"
        logger.error(f"ä¸»æµç¨‹æ‰§è¡Œå¤±è´¥: {error_msg}")
        raise HTTPException(
            status_code=500,
            detail=f"ä¸»æµç¨‹æ‰§è¡Œå¤±è´¥: {error_msg}"
        )


@app.post("/upload-and-trigger")
async def upload_and_trigger(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    output_dir: str = "data"
):
    """ä¸Šä¼ mitmæ–‡ä»¶å¹¶è§¦å‘ä¸»æµç¨‹ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰"""
    global server_state

    # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œ
    if server_state.status == "running":
        raise HTTPException(
            status_code=400,
            detail="å·²æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œè¯·ç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆæˆ–é‡ç½®çŠ¶æ€"
        )

    # éªŒè¯æ–‡ä»¶ç±»å‹
    if not file.filename.endswith('.mitm'):
        raise HTTPException(
            status_code=400,
            detail="åªæ”¯æŒ.mitmæ ¼å¼çš„æ–‡ä»¶"
        )

    try:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        upload_dir = "uploads"
        os.makedirs(upload_dir, exist_ok=True)

        timestamp = int(time.time())
        safe_filename = f"upload_{timestamp}_{file.filename}"
        file_path = os.path.join(upload_dir, safe_filename)

        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)

        logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_path} ({len(content)} bytes)")

        # æ„å»ºé…ç½®
        config = {
            'output_dir': output_dir,
            'temp_dir': 'temp'
        }

        # å¯åŠ¨åå°ä»»åŠ¡ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰
        background_tasks.add_task(run_pipeline_async, config, True, file_path)

        return APIResponse(
            success=True,
            message=f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œä¸»æµç¨‹å·²è§¦å‘ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰",
            data={
                "task_id": server_state.current_task_id,
                "uploaded_file": file_path,
                "file_size": len(content),
                "config": config,
                "status": server_state.status
            }
        )

    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}"
        )


@app.get("/providers")
async def get_providers():
    """è·å–æœ€æ–°çš„Provideråˆ—è¡¨"""
    try:
        # æŸ¥æ‰¾æœ€æ–°çš„reclaim_providersæ–‡ä»¶ (é›†æˆä¸»æµç¨‹ç”Ÿæˆçš„æ ¼å¼)
        data_dir = "data"
        if not os.path.exists(data_dir):
            return APIResponse(
                success=False,
                message="æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ‰§è¡Œä¸»æµç¨‹",
                data={}
            )

        provider_files = []
        for file in os.listdir(data_dir):
            # æŸ¥æ‰¾é›†æˆä¸»æµç¨‹ç”Ÿæˆçš„reclaim_providersæ–‡ä»¶
            if file.startswith("reclaim_providers_") and file.endswith(".json"):
                file_path = os.path.join(data_dir, file)
                provider_files.append((file_path, os.path.getmtime(file_path)))

        if not provider_files:
            return APIResponse(
                success=False,
                message="æœªæ‰¾åˆ°Provideré…ç½®æ–‡ä»¶ï¼Œè¯·å…ˆæ‰§è¡Œä¸»æµç¨‹",
                data={}
            )

        # è·å–æœ€æ–°çš„æ–‡ä»¶
        latest_file = max(provider_files, key=lambda x: x[1])[0]

        with open(latest_file, 'r', encoding='utf-8') as f:
            providers_data = json.load(f)

        # æå–providersæ•°ç»„å’Œå…ƒæ•°æ®
        providers_array = providers_data.get('providers', [])
        metadata = providers_data.get('metadata', {})

        # ä½¿ç”¨ç»Ÿä¸€æ’åºå‡½æ•°è¿›è¡Œå€’åºæ’åºï¼Œæœ€æ–°çš„æ”¾åœ¨å‰é¢
        sorted_providers = sort_providers_by_time(providers_array, reverse=True)

        return APIResponse(
            success=True,
            message=f"æˆåŠŸè·å–Provideråˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´å€’åºæ’åºï¼‰",
            data={
                "providers": sorted_providers,
                "metadata": metadata,
                "file_path": latest_file,
                "providers_count": len(sorted_providers),
                "total_providers": metadata.get('total_providers', len(sorted_providers)),
                "last_modified": datetime.fromtimestamp(os.path.getmtime(latest_file)).isoformat()
            }
        )

    except Exception as e:
        logger.error(f"è·å–Provideråˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"è·å–Provideråˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@app.get("/files")
async def list_files():
    """åˆ—å‡ºæ‰€æœ‰è¾“å‡ºæ–‡ä»¶"""
    try:
        files_info = []

        # æ‰«ædataç›®å½•
        data_dir = "data"
        if os.path.exists(data_dir):
            for file in os.listdir(data_dir):
                if file.endswith('.json'):
                    file_path = os.path.join(data_dir, file)
                    stat = os.stat(file_path)
                    files_info.append({
                        "filename": file,
                        "path": file_path,
                        "size": stat.st_size,
                        "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        "type": "output"
                    })

        # æ‰«æuploadsç›®å½•
        uploads_dir = "uploads"
        if os.path.exists(uploads_dir):
            for file in os.listdir(uploads_dir):
                if file.endswith('.mitm'):
                    file_path = os.path.join(uploads_dir, file)
                    stat = os.stat(file_path)
                    files_info.append({
                        "filename": file,
                        "path": file_path,
                        "size": stat.st_size,
                        "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        "type": "upload"
                    })

        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        files_info.sort(key=lambda x: x['modified'], reverse=True)

        return APIResponse(
            success=True,
            message=f"æ‰¾åˆ° {len(files_info)} ä¸ªæ–‡ä»¶",
            data={
                "files": files_info,
                "total_count": len(files_info)
            }
        )

    except Exception as e:
        logger.error(f"åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {str(e)}"
        )


@app.get("/download/{file_type}/{filename}")
async def download_file(file_type: str, filename: str):
    """ä¸‹è½½æ–‡ä»¶"""
    try:
        # éªŒè¯æ–‡ä»¶ç±»å‹
        if file_type == "output":
            base_dir = "data"
        elif file_type == "upload":
            base_dir = "uploads"
        else:
            raise HTTPException(status_code=400, detail="æ— æ•ˆçš„æ–‡ä»¶ç±»å‹")

        file_path = os.path.join(base_dir, filename)

        # éªŒè¯æ–‡ä»¶å­˜åœ¨ä¸”åœ¨å…è®¸çš„ç›®å½•å†…
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶åœ¨æŒ‡å®šç›®å½•å†…
        if not os.path.abspath(file_path).startswith(os.path.abspath(base_dir)):
            raise HTTPException(status_code=403, detail="è®¿é—®è¢«æ‹’ç»")

        return FileResponse(
            path=file_path,
            filename=filename,
            media_type='application/octet-stream'
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {str(e)}"
        )


def main():
    """å¯åŠ¨APIæœåŠ¡å™¨"""
    # åŠ¨æ€è·å–æœ¬æœºIP
    local_ip = get_local_ip()
    port = 8000

    print("ğŸš€ å¯åŠ¨é“¶è¡ŒProviderç”ŸæˆAPIæœåŠ¡å™¨")
    print("=" * 70)
    print(f"ğŸ“ æœ¬æœºIPåœ°å€: {local_ip}")
    print(f"ğŸŒ æœåŠ¡åœ°å€: http://{local_ip}:{port}")
    print(f"ğŸ“– APIæ–‡æ¡£: http://{local_ip}:{port}/docs")
    print(f"ğŸ” å¥åº·æ£€æŸ¥: http://{local_ip}:{port}/health")
    print(f"ğŸ§ª æµ‹è¯•ç•Œé¢: æ‰“å¼€ api_test_client.html")
    print("=" * 70)
    print("ğŸ’¡ è¿™æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„APIæœåŠ¡ï¼Œä¸ä¾èµ–mitmproxyæ’ä»¶")
    print("ğŸ›‘ æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print()

    # å¯åŠ¨æœåŠ¡å™¨ï¼Œç›‘å¬æ‰€æœ‰æ¥å£
    uvicorn.run(
        "independent_api_server:app",
        host="0.0.0.0",
        port=port,
        reload=False,
        log_level="info"
    )


if __name__ == "__main__":
    main()