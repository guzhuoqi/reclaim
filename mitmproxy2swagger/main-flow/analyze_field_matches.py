#!/usr/bin/env python3
"""
åˆ†ææŠ“åŒ…æ–‡ä»¶ä¸­ç‰¹å®šå­—æ®µçš„åŒ¹é…æƒ…å†µ
Analyze field matches in captured traffic files
"""

import json
import os
import sys
from pathlib import Path
from mitmproxy import io, http
from mitmproxy.exceptions import FlowReadException
import re
from collections import defaultdict, Counter

def analyze_response_content(content: str, patterns: dict) -> dict:
    """åˆ†æå“åº”å†…å®¹ä¸­çš„æ¨¡å¼åŒ¹é…"""
    matches = {}

    for field_name, pattern_info in patterns.items():
        pattern_type = pattern_info.get('type', 'contains')
        pattern_value = pattern_info.get('value', '')
        invert = pattern_info.get('invert', False)

        if pattern_type == 'contains':
            # ç§»é™¤å¼•å·è¿›è¡ŒåŒ¹é…
            search_value = pattern_value.strip('"')
            found = search_value in content

            if invert:
                found = not found

            matches[field_name] = {
                'found': found,
                'pattern': pattern_value,
                'type': pattern_type,
                'invert': invert
            }

            # å¦‚æœæ‰¾åˆ°åŒ¹é…ï¼Œå°è¯•æå–ä¸Šä¸‹æ–‡
            if found and not invert:
                # æŸ¥æ‰¾åŒ…å«è¯¥å­—æ®µçš„JSONç‰‡æ®µ
                json_contexts = extract_json_contexts(content, search_value)
                if json_contexts:
                    matches[field_name]['contexts'] = json_contexts[:3]  # æœ€å¤š3ä¸ªä¸Šä¸‹æ–‡

    return matches

def extract_json_contexts(content: str, field_name: str) -> list:
    """æå–åŒ…å«æŒ‡å®šå­—æ®µçš„JSONä¸Šä¸‹æ–‡"""
    contexts = []

    # å°è¯•è§£ææ•´ä¸ªå“åº”ä¸ºJSON
    try:
        json_data = json.loads(content)
        contexts.extend(find_field_in_json(json_data, field_name))
    except:
        # å¦‚æœä¸æ˜¯å®Œæ•´JSONï¼Œå°è¯•æŸ¥æ‰¾JSONç‰‡æ®µ
        json_pattern = r'\{[^{}]*"' + re.escape(field_name) + r'"[^{}]*\}'
        matches = re.finditer(json_pattern, content)

        for match in matches:
            try:
                json_fragment = json.loads(match.group())
                contexts.append(json_fragment)
            except:
                # å¦‚æœJSONç‰‡æ®µæ— æ•ˆï¼Œä¿å­˜åŸå§‹æ–‡æœ¬
                contexts.append(match.group())

        if len(contexts) == 0:
            # æŸ¥æ‰¾ç®€å•çš„é”®å€¼å¯¹
            simple_pattern = r'"' + re.escape(field_name) + r'":\s*"[^"]*"'
            simple_matches = re.findall(simple_pattern, content)
            contexts.extend(simple_matches[:3])

    return contexts

def find_field_in_json(data, field_name: str, path: str = "") -> list:
    """é€’å½’æŸ¥æ‰¾JSONä¸­çš„å­—æ®µ"""
    results = []

    if isinstance(data, dict):
        for key, value in data.items():
            current_path = f"{path}.{key}" if path else key

            if key == field_name:
                results.append({
                    'path': current_path,
                    'value': value,
                    'context': {k: v for k, v in data.items() if k != field_name}
                })

            if isinstance(value, (dict, list)):
                results.extend(find_field_in_json(value, field_name, current_path))

    elif isinstance(data, list):
        for i, item in enumerate(data):
            current_path = f"{path}[{i}]" if path else f"[{i}]"
            if isinstance(item, (dict, list)):
                results.extend(find_field_in_json(item, field_name, current_path))

    return results

def analyze_mitm_file(file_path: str, patterns: dict) -> dict:
    """åˆ†æå•ä¸ªmitmæ–‡ä»¶"""
    print(f"\nğŸ” åˆ†ææ–‡ä»¶: {file_path}")

    results = {
        'file_path': file_path,
        'total_flows': 0,
        'analyzed_responses': 0,
        'field_matches': defaultdict(list),
        'summary': defaultdict(int)
    }

    try:
        with open(file_path, "rb") as f:
            flow_reader = io.FlowReader(f)

            for flow in flow_reader.stream():
                if isinstance(flow, http.HTTPFlow):
                    results['total_flows'] += 1

                    # åˆ†æå“åº”
                    if flow.response and flow.response.content:
                        try:
                            response_text = flow.response.get_text()
                            if response_text:
                                results['analyzed_responses'] += 1

                                # åˆ†æå­—æ®µåŒ¹é…
                                matches = analyze_response_content(response_text, patterns)

                                for field_name, match_info in matches.items():
                                    if match_info['found']:
                                        results['field_matches'][field_name].append({
                                            'url': flow.request.pretty_url,
                                            'method': flow.request.method,
                                            'status_code': flow.response.status_code,
                                            'content_type': flow.response.headers.get('content-type', ''),
                                            'match_info': match_info,
                                            'response_size': len(response_text)
                                        })
                                        results['summary'][field_name] += 1
                        except Exception as e:
                            print(f"   âš ï¸  å“åº”è§£æé”™è¯¯: {e}")

    except FlowReadException as e:
        print(f"   âŒ æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
        return None
    except Exception as e:
        print(f"   âŒ åˆ†æé”™è¯¯: {e}")
        return None

    print(f"   ğŸ“Š æ€»æµé‡: {results['total_flows']}, åˆ†æå“åº”: {results['analyzed_responses']}")
    for field_name, count in results['summary'].items():
        print(f"   ğŸ¯ {field_name}: {count} æ¬¡åŒ¹é…")

    return results

def main():
    # å®šä¹‰è¦åˆ†æçš„å­—æ®µæ¨¡å¼
    patterns = {
        'currency': {
            'type': 'contains',
            'value': '"currency"',
            'invert': False
        },
        'phone': {
            'type': 'contains',
            'value': '"phone"',
            'invert': False
        },
        'email': {
            'type': 'contains',
            'value': '"email"',
            'invert': False
        }
    }

    print("ğŸ” æŠ“åŒ…æ–‡ä»¶å­—æ®µåŒ¹é…åˆ†æ")
    print("=" * 50)
    print("åˆ†æå­—æ®µ:")
    for field_name, pattern_info in patterns.items():
        print(f"  â€¢ {field_name}: {pattern_info['value']}")
    print()

    # æŸ¥æ‰¾æ‰€æœ‰mitmæ–‡ä»¶
    current_dir = Path(__file__).parent
    mitm_files = []

    # åœ¨tempç›®å½•ä¸­æŸ¥æ‰¾
    temp_dir = current_dir / 'temp'
    if temp_dir.exists():
        mitm_files.extend(temp_dir.glob('*.mitm'))

    # åœ¨testdataç›®å½•ä¸­æŸ¥æ‰¾
    testdata_dir = current_dir.parent / 'testdata'
    if testdata_dir.exists():
        mitm_files.extend(testdata_dir.glob('*.mitm'))

    if not mitm_files:
        print("âŒ æœªæ‰¾åˆ°mitmæ–‡ä»¶")
        return

    print(f"ğŸ“ æ‰¾åˆ° {len(mitm_files)} ä¸ªmitmæ–‡ä»¶")

    # åˆ†ææ‰€æœ‰æ–‡ä»¶
    all_results = []
    overall_summary = defaultdict(int)

    for mitm_file in sorted(mitm_files):
        result = analyze_mitm_file(str(mitm_file), patterns)
        if result:
            all_results.append(result)
            for field_name, count in result['summary'].items():
                overall_summary[field_name] += count

    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\n" + "=" * 50)
    print("ğŸ“Š æ€»ç»“æŠ¥å‘Š")
    print("=" * 50)

    total_flows = sum(r['total_flows'] for r in all_results)
    total_responses = sum(r['analyzed_responses'] for r in all_results)

    print(f"ğŸ“ åˆ†ææ–‡ä»¶æ•°: {len(all_results)}")
    print(f"ğŸ“Š æ€»æµé‡æ•°: {total_flows}")
    print(f"ğŸ“„ åˆ†æå“åº”æ•°: {total_responses}")
    print()

    print("ğŸ¯ å­—æ®µåŒ¹é…ç»Ÿè®¡:")
    for field_name in patterns.keys():
        count = overall_summary[field_name]
        percentage = (count / total_responses * 100) if total_responses > 0 else 0
        print(f"  â€¢ {field_name}: {count} æ¬¡åŒ¹é… ({percentage:.1f}%)")

    # ä¿å­˜è¯¦ç»†ç»“æœ
    try:
        import pandas as pd
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
    except:
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    output_file = current_dir / 'data' / f'field_match_analysis_{timestamp}.json'

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'analysis_timestamp': timestamp,
            'patterns': patterns,
            'overall_summary': dict(overall_summary),
            'total_files': len(all_results),
            'total_flows': total_flows,
            'total_responses': total_responses,
            'detailed_results': all_results
        }, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

if __name__ == "__main__":
    main()
