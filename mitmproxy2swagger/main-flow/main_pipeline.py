#!/usr/bin/env python3
"""
ä¸»æµç¨‹ç®¡é“å™¨
å®Œæ•´çš„é“¶è¡ŒProviderç”Ÿæˆä¸»æµç¨‹ï¼šä»mitmproxyå¯¼å‡º -> åˆ†ææå– -> æ„å»ºProvider

ä¸»è¦åŠŸèƒ½ï¼š
1. æ£€æµ‹mitmä»£ç†æœåŠ¡çŠ¶æ€
2. å¯¼å‡ºæŠ“åŒ…æ–‡ä»¶
3. åˆ†ææŠ“åŒ…æ–‡ä»¶å¹¶æå–é“¶è¡Œå‚æ•°
4. æ„å»ºæ ‡å‡†Reclaimåè®®Provideré…ç½®
5. è¾“å‡ºå®Œæ•´çš„Providerå¯¹è±¡åˆ—è¡¨

ä½¿ç”¨æ–¹å¼ï¼š
- è‡ªåŠ¨æ¨¡å¼ï¼špython3 main_pipeline.py
- æŒ‡å®šé…ç½®ï¼špython3 main_pipeline.py --mitm-host 10.10.10.146 --mitm-port 8082
- ç¦»çº¿æ¨¡å¼ï¼špython3 main_pipeline.py --offline --input-file flows.mitm
"""

import os
import sys
import json
import time
import requests
import argparse
import subprocess
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from urllib.parse import urljoin
from pathlib import Path

# ç¡®ä¿logsç›®å½•å­˜åœ¨
os.makedirs('logs', exist_ok=True)

# é…ç½®æ—¥å¿— - å†™å…¥logsç›®å½•
log_filename = f'logs/main_pipeline_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—  
from feature_library_pipeline import FeatureLibraryPipeline
from dynamic_config import dynamic_config



class MainPipeline:
    """ä¸»æµç¨‹ç®¡é“å™¨"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        
        # é»˜è®¤é…ç½® - ä½¿ç”¨åŠ¨æ€é…ç½®ç®¡ç†å™¨
        self.default_config = {
            'mitm_host': dynamic_config.get_mitm_host(),
            'mitm_port': dynamic_config.get_mitm_port(),
            'output_dir': 'data',
            'temp_dir': 'temp',
            'testdata_dir': '../testdata'
        }
        
        # åˆå¹¶é…ç½®
        for key, value in self.default_config.items():
            if key not in self.config:
                self.config[key] = value
        
        # ä¸ provider_query ä¸€è‡´çš„ data ç›®å½•æ£€æµ‹
        def detect_data_dir() -> str:
            env_dir = os.getenv('MAIN_FLOW_DATA_DIR')
            if env_dir and os.path.exists(env_dir):
                return os.path.abspath(env_dir)
            container_dir = "/app/main-flow/data"
            if os.path.exists(container_dir):
                return container_dir
            relative_dir = str((Path(__file__).resolve().parent.parent / "main-flow" / "data").resolve())
            if os.path.exists(relative_dir):
                return relative_dir
            fallback = str((Path(__file__).resolve().parent / "data").resolve())
            return fallback

        if 'output_dir' not in self.config or self.config.get('output_dir') in ('data', './data'):
            self.config['output_dir'] = detect_data_dir()

        # å½’ä¸€åŒ–ç›®å½•ä¸ºç»å¯¹è·¯å¾„
        base_dir = Path(__file__).resolve().parent
        for dir_key in ['output_dir', 'temp_dir']:
            dir_path = self.config.get(dir_key)
            if isinstance(dir_path, str) and not os.path.isabs(dir_path):
                self.config[dir_key] = str((base_dir / dir_path).resolve())

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.ensure_directories()
        
        # æµç¨‹çŠ¶æ€
        self.pipeline_state = {
            'mitm_status': 'unknown',
            'export_file': None,
            'extracted_providers': None,
            'final_providers': None,
            'steps_completed': [],
            'errors': []
        }
    
    def ensure_directories(self):
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        for dir_key in ['output_dir', 'temp_dir']:
            dir_path = self.config[dir_key]
            if not os.path.exists(dir_path):
                os.makedirs(dir_path)
                print(f"âœ… åˆ›å»ºç›®å½•: {dir_path}")
    
    def check_mitm_proxy_status(self) -> Tuple[bool, str]:
        """
        æ£€æµ‹mitmproxyæœåŠ¡çŠ¶æ€
        
        Returns:
            (is_running: bool, status_message: str)
        """
        mitm_host = self.config['mitm_host']
        mitm_port = self.config['mitm_port']
        
        try:
            # æ£€æŸ¥æµé‡å¯¼å‡ºæ¥å£
            url = f"http://{mitm_host}:{mitm_port}/flows/dump"
            
            print(f"ğŸ” æ£€æµ‹mitmä»£ç†çŠ¶æ€: {mitm_host}:{mitm_port}")
            
            response = requests.get(url, timeout=5)
            
            if response.status_code == 200:
                # æ£€æŸ¥å“åº”å†…å®¹é•¿åº¦
                content_length = len(response.content)
                self.pipeline_state['mitm_status'] = 'running'
                status_msg = f"âœ… mitmä»£ç†è¿è¡Œæ­£å¸¸ï¼Œå½“å‰æµé‡æ•°æ®: {content_length} bytes"
                print(status_msg)
                return True, status_msg
            else:
                error_msg = f"âŒ mitmä»£ç†å“åº”å¼‚å¸¸: HTTP {response.status_code}"
                print(error_msg)
                return False, error_msg
                
        except requests.exceptions.ConnectionError:
            error_msg = f"âŒ æ— æ³•è¿æ¥åˆ°mitmä»£ç†: {mitm_host}:{mitm_port}"
            print(error_msg)
            self.pipeline_state['mitm_status'] = 'connection_failed'
            return False, error_msg
            
        except requests.exceptions.Timeout:
            error_msg = f"âŒ mitmä»£ç†è¿æ¥è¶…æ—¶: {mitm_host}:{mitm_port}"
            print(error_msg)
            self.pipeline_state['mitm_status'] = 'timeout'
            return False, error_msg
            
        except Exception as e:
            error_msg = f"âŒ mitmä»£ç†æ£€æµ‹å¤±è´¥: {e}"
            print(error_msg)
            self.pipeline_state['mitm_status'] = 'error'
            return False, error_msg
    
    def export_mitm_flows(self, output_file: str = None) -> Optional[str]:
        """
        ä»mitmproxyå¯¼å‡ºæµé‡æ•°æ®
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            å¯¼å‡ºçš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        if not output_file:
            timestamp = int(time.time())
            # ä¸ Docker å·æŒ‚è½½ä¿æŒä¸€è‡´ï¼šé»˜è®¤å¯¼å‡ºåˆ°ç»å¯¹çš„ output_dir (data)
            output_file = os.path.join(self.config.get('output_dir', str((Path(__file__).resolve().parent / 'data').resolve())), f"flows_export_{timestamp}.mitm")
        else:
            output_file = os.path.abspath(output_file)
        
        mitm_host = self.config['mitm_host']
        mitm_port = self.config['mitm_port']
        url = f"http://{mitm_host}:{mitm_port}/flows/dump"
        
        try:
            print(f"ğŸ“¥ å¼€å§‹å¯¼å‡ºæµé‡æ•°æ®...")
            print(f"   æºåœ°å€: {url}")
            print(f"   ç›®æ ‡æ–‡ä»¶: {output_file}")
            
            # ä½¿ç”¨curlå‘½ä»¤å¯¼å‡ºï¼ˆæ›´ç¨³å®šï¼‰
            curl_cmd = [
                'curl', '-s', 
                f'http://{mitm_host}:{mitm_port}/flows/dump'
            ]
            
            with open(output_file, 'wb') as f:
                result = subprocess.run(curl_cmd, stdout=f, stderr=subprocess.PIPE)
            
            if result.returncode == 0:
                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                file_size = os.path.getsize(output_file)
                if file_size > 0:
                    print(f"âœ… æˆåŠŸå¯¼å‡ºæµé‡æ•°æ®: {file_size} bytes")
                    self.pipeline_state['export_file'] = os.path.abspath(output_file)
                    self.pipeline_state['steps_completed'].append('export')
                    return output_file
                else:
                    print(f"âš ï¸  å¯¼å‡ºçš„æ–‡ä»¶ä¸ºç©º")
                    return None
            else:
                error_msg = result.stderr.decode() if result.stderr else "æœªçŸ¥é”™è¯¯"
                print(f"âŒ curlå¯¼å‡ºå¤±è´¥: {error_msg}")
                return None
                
        except Exception as e:
            print(f"âŒ å¯¼å‡ºæµé‡æ•°æ®å¤±è´¥: {e}")
            self.pipeline_state['errors'].append(f"å¯¼å‡ºå¤±è´¥: {e}")
            return None
    
    def extract_bank_parameters(self, mitm_file: str) -> Optional[Dict]:
        """
        æå–é“¶è¡Œå‚æ•° - ä½¿ç”¨ç‰¹å¾åº“åº”ç”¨2.0æµç¨‹
        
        Args:
            mitm_file: mitmproxyæ–‡ä»¶è·¯å¾„
            
        Returns:
            æå–ç»“æœå­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            print(f"ğŸ”„ å¼€å§‹ç‰¹å¾åº“åº”ç”¨2.0æµç¨‹ (ä¸‰è½®å®Œæ•´å¤„ç†)...")
            
            # åˆ›å»ºç‰¹å¾åº“åº”ç”¨2.0æµç¨‹ç®¡é“å™¨
            pipeline = FeatureLibraryPipeline(mitm_file, self.config['output_dir'])
            
            # è¿è¡Œå®Œæ•´çš„ä¸‰è½®æµç¨‹ (è·³è¿‡AIåˆ†æä»¥æé«˜é€Ÿåº¦)
            result = pipeline.run_full_pipeline(skip_ai_analysis=True)
            
            if result['success']:
                # è½¬æ¢ç»“æœæ ¼å¼ä»¥å…¼å®¹ç°æœ‰æ¥å£
                output_files = result.get('output_files', {})
                providers_file = output_files.get('providers', '')
                
                # ä»Provideræ–‡ä»¶ä¸­è¯»å–ç»Ÿè®¡ä¿¡æ¯
                provider_count = 0
                if providers_file and os.path.exists(providers_file):
                    try:
                        with open(providers_file, 'r', encoding='utf-8') as f:
                            provider_data = json.load(f)
                            provider_count = provider_data.get('metadata', {}).get('total_providers', 0)
                    except Exception as e:
                        logger.warning(f"è¯»å–Providerç»Ÿè®¡å¤±è´¥: {e}")
                
                # æ„å»ºå…¼å®¹çš„è¿”å›æ ¼å¼
                compatible_result = {
                    'success': True,
                    'reclaim_providers_count': provider_count,
                    'attestor_providers_count': 0,  # å½“å‰ç‰ˆæœ¬ä¸»è¦ç”ŸæˆReclaim Provider
                    'output_files': output_files,
                    'pipeline_report': result.get('report', {}),
                    'message': 'ç‰¹å¾åº“åº”ç”¨2.0æµç¨‹æ‰§è¡ŒæˆåŠŸ'
                }
                
                print(f"âœ… ç‰¹å¾åº“åº”ç”¨2.0æµç¨‹æˆåŠŸ:")
                print(f"   Reclaim Provider: {provider_count} ä¸ª")
                print(f"   è¾“å‡ºæ–‡ä»¶: {len(output_files)} ä¸ª")
                logger.info(f"ç‰¹å¾åº“åº”ç”¨2.0æˆåŠŸ - Provider: {provider_count}, æ–‡ä»¶: {len(output_files)}")
                
                self.pipeline_state['extracted_providers'] = compatible_result
                self.pipeline_state['steps_completed'].append('extract')
                return compatible_result
            else:
                error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                print(f"âŒ ç‰¹å¾åº“åº”ç”¨2.0æµç¨‹å¤±è´¥: {error_msg}")
                logger.error(f"ç‰¹å¾åº“åº”ç”¨2.0å¤±è´¥: {error_msg}")
                return None
                
        except Exception as e:
            print(f"âŒ ç‰¹å¾åº“åº”ç”¨2.0æµç¨‹å¼‚å¸¸: {e}")
            logger.error(f"ç‰¹å¾åº“åº”ç”¨2.0å¼‚å¸¸: {e}")
            self.pipeline_state['errors'].append(f"ç‰¹å¾åº“æµç¨‹å¼‚å¸¸: {e}")
            return None
    
    def build_providers(self, extract_result: Dict = None) -> Optional[Dict]:
        """
        æ„å»ºReclaim Provideré…ç½®
        
        Args:
            extract_result: æå–ç»“æœï¼Œå¦‚æœä¸ºNoneåˆ™æŸ¥æ‰¾æœ€æ–°çš„é…ç½®æ–‡ä»¶
            
        Returns:
            æ„å»ºç»“æœå­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            print(f"ğŸ—ï¸  å¼€å§‹æ„å»ºReclaim Provideré…ç½®...")
            
            print(f"ğŸ’¡ ä½¿ç”¨ç‰¹å¾åº“åº”ç”¨2.0çš„è¾“å‡ºä½œä¸ºæœ€ç»ˆç»“æœ")
            
            # ä½¿ç”¨æ™ºèƒ½æå–ç»“æœä½œä¸ºæ„å»ºç»“æœ
            if extract_result and extract_result.get('success'):
                result = {
                    'success': True,
                    'reclaim_providers_count': extract_result.get('reclaim_providers_count', 0),
                    'attestor_providers_count': extract_result.get('attestor_providers_count', 0),
                    'output_files': extract_result.get('output_files', {}),
                    'message': 'ä½¿ç”¨æå–ç»“æœä½œä¸ºæœ€ç»ˆProvideré…ç½®'
                }
                
                print(f"âœ… ä½¿ç”¨æå–çš„Provideré…ç½®:")
                print(f"   Reclaim: {result['reclaim_providers_count']} ä¸ª")
                print(f"   Attestor: {result['attestor_providers_count']} ä¸ª")
                self.pipeline_state['final_providers'] = result
                self.pipeline_state['steps_completed'].append('build')
                return result
            else:
                print(f"âŒ æ— æ³•è·å–æå–ç»“æœè¿›è¡Œæ„å»º")
                return None
                
        except Exception as e:
            print(f"âŒ Provideré…ç½®æ„å»ºå¼‚å¸¸: {e}")
            self.pipeline_state['errors'].append(f"Provideræ„å»ºå¼‚å¸¸: {e}")
            return None
    
    def generate_pipeline_report(self) -> Dict:
        """ç”Ÿæˆæµç¨‹æ‰§è¡ŒæŠ¥å‘Š"""
        report = {
            "pipeline_report": {
                "execution_time": datetime.now().isoformat(),
                "mitm_config": {
                    "host": self.config['mitm_host'],
                    "port": self.config['mitm_port'],
                    "status": self.pipeline_state['mitm_status']
                },
                "steps_completed": self.pipeline_state['steps_completed'],
                "steps_total": ["export", "extract", "build"],
                "success_rate": len(self.pipeline_state['steps_completed']) / 3,
                "errors": self.pipeline_state['errors']
            },
            "results": {
                "export_file": self.pipeline_state['export_file'],
                "reclaim_providers_extracted": self.pipeline_state['extracted_providers']['reclaim_providers_count'] if self.pipeline_state['extracted_providers'] else 0,
            "attestor_providers_extracted": self.pipeline_state['extracted_providers']['attestor_providers_count'] if self.pipeline_state['extracted_providers'] else 0,
                "reclaim_providers_built": self.pipeline_state['final_providers']['reclaim_providers_count'] if self.pipeline_state['final_providers'] else 0,
            "attestor_providers_built": self.pipeline_state['final_providers']['attestor_providers_count'] if self.pipeline_state['final_providers'] else 0,
                "final_output_files": self.pipeline_state['final_providers']['output_files'] if self.pipeline_state['final_providers'] else {}
            }
        }
        
        return report
    
    def save_pipeline_report(self, report: Dict) -> str:
        """ä¿å­˜æµç¨‹æŠ¥å‘Š"""
        timestamp = int(time.time())
        report_file = os.path.join(self.config['output_dir'], f"pipeline_report_{timestamp}.json")
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ“Š æµç¨‹æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            return report_file
            
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜æµç¨‹æŠ¥å‘Šå¤±è´¥: {e}")
            return ""
    
    def run_full_pipeline(self, offline_mode: bool = False, input_file: str = None) -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„ä¸»æµç¨‹
        
        Args:
            offline_mode: ç¦»çº¿æ¨¡å¼ï¼Œä¸æ£€æµ‹mitmä»£ç†
            input_file: æŒ‡å®šè¾“å…¥æ–‡ä»¶ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰
            
        Returns:
            æµç¨‹æ‰§è¡Œç»“æœ
        """
        print("ğŸš€ å¯åŠ¨é“¶è¡ŒProviderç”Ÿæˆä¸»æµç¨‹...")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.config['output_dir']}")
        print("=" * 70)
        
        # æ­¥éª¤1: æ£€æµ‹mitmä»£ç†å’Œå¯¼å‡ºæ•°æ®ï¼ˆå¦‚æœä¸æ˜¯ç¦»çº¿æ¨¡å¼ï¼‰
        if not offline_mode:
            # æ£€æµ‹mitmä»£ç†
            mitm_running, status_msg = self.check_mitm_proxy_status()
            
            if not mitm_running:
                print(f"ğŸ’¡ æç¤º: å¦‚éœ€ç¦»çº¿æ¨¡å¼ï¼Œè¯·ä½¿ç”¨ --offline --input-file <file>")
                return {
                    "success": False,
                    "message": "mitmä»£ç†æœªè¿è¡Œ",
                    "report": self.generate_pipeline_report()
                }
            
            # å¯¼å‡ºæµé‡æ•°æ®
            export_file = self.export_mitm_flows()
            if not export_file:
                return {
                    "success": False,
                    "message": "æµé‡æ•°æ®å¯¼å‡ºå¤±è´¥",
                    "report": self.generate_pipeline_report()
                }
        else:
            # ç¦»çº¿æ¨¡å¼ï¼Œä½¿ç”¨æŒ‡å®šçš„è¾“å…¥æ–‡ä»¶
            if not input_file or not os.path.exists(input_file):
                return {
                    "success": False,
                    "message": f"ç¦»çº¿æ¨¡å¼ä¸‹æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {input_file}",
                    "report": self.generate_pipeline_report()
                }
            
            export_file = input_file
            print(f"ğŸ“„ ç¦»çº¿æ¨¡å¼ï¼Œä½¿ç”¨è¾“å…¥æ–‡ä»¶: {export_file}")
            self.pipeline_state['export_file'] = export_file
            self.pipeline_state['steps_completed'].append('export')
        
        print("-" * 70)
        
        # æ­¥éª¤2: æå–é“¶è¡Œå‚æ•° - ä½¿ç”¨åŸå§‹è¾“å…¥æ–‡ä»¶è€Œä¸æ˜¯å¯¼å‡ºæ–‡ä»¶
        original_input_file = input_file if input_file else None
        if not original_input_file:
            # å¦‚æœæ²¡æœ‰åŸå§‹æ–‡ä»¶ï¼Œåˆ™ä½¿ç”¨å¯¼å‡ºæ–‡ä»¶ï¼Œä½†è¿™ä¸æ˜¯æœ€ä¼˜çš„
            print("âš ï¸  è­¦å‘Š: ä½¿ç”¨å¯¼å‡ºæ–‡ä»¶è€ŒéåŸå§‹æ–‡ä»¶ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
            original_input_file = export_file
        
        extract_result = self.extract_bank_parameters(original_input_file)
        if not extract_result:
            return {
                "success": False,
                "message": "é“¶è¡Œå‚æ•°æå–å¤±è´¥",
                "report": self.generate_pipeline_report()
            }
        
        print("-" * 70)
        
        # æ­¥éª¤3: æ„å»ºProvideré…ç½®
        build_result = self.build_providers(extract_result)
        if not build_result:
            return {
                "success": False,
                "message": "Provideré…ç½®æ„å»ºå¤±è´¥",
                "report": self.generate_pipeline_report()
            }
        
        print("=" * 70)
        print("ğŸ‰ ä¸»æµç¨‹æ‰§è¡Œå®Œæˆ!")
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        final_report = self.generate_pipeline_report()
        report_file = self.save_pipeline_report(final_report)
        
        print(f"ğŸ“Š å¤„ç†ç»“æœ:")
        print(f"   ğŸ¦ Reclaim Provider: {final_report['results']['reclaim_providers_extracted']}")
        print(f"   ğŸ¦ Attestor Provider: {final_report['results']['attestor_providers_extracted']}")
        print(f"   ğŸ“„ Reclaim ç”Ÿæˆ: {final_report['results']['reclaim_providers_built']}")
        print(f"   ğŸ“„ Attestor ç”Ÿæˆ: {final_report['results']['attestor_providers_built']}")
        print(f"   ğŸ“ è¾“å‡ºæ–‡ä»¶: {final_report['results']['final_output_files']}")
        print(f"   ğŸ“‹ æ‰§è¡ŒæŠ¥å‘Š: {report_file}")
        
        return {
            "success": True,
            "message": "ä¸»æµç¨‹æ‰§è¡ŒæˆåŠŸ",
            "report": final_report,
            "output_files": final_report['results']['final_output_files']
        }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é“¶è¡ŒProviderç”Ÿæˆä¸»æµç¨‹")
    
    # mitmé…ç½®
    parser.add_argument('--mitm-host', default=dynamic_config.get_mitm_host(),
                       help=f'mitmproxyä¸»æœºåœ°å€ (é»˜è®¤: {dynamic_config.get_mitm_host()})')
    parser.add_argument('--mitm-port', type=int, default=dynamic_config.get_mitm_port(),
                       help=f'mitmproxyç«¯å£å· (é»˜è®¤: {dynamic_config.get_mitm_port()})')
    
    # ç¦»çº¿æ¨¡å¼
    parser.add_argument('--offline', action='store_true',
                       help='ç¦»çº¿æ¨¡å¼ï¼Œä¸æ£€æµ‹mitmä»£ç†')
    parser.add_argument('--input-file', 
                       help='ç¦»çº¿æ¨¡å¼çš„è¾“å…¥æ–‡ä»¶è·¯å¾„')
    
    # è¾“å‡ºé…ç½®
    parser.add_argument('--output-dir', default='data',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: data)')
    
    # è°ƒè¯•é€‰é¡¹
    parser.add_argument('--verbose', action='store_true',
                       help='è¯¦ç»†è¾“å‡ºæ¨¡å¼')
    
    args = parser.parse_args()
    
    # éªŒè¯ç¦»çº¿æ¨¡å¼å‚æ•°
    if args.offline and not args.input_file:
        print("âŒ é”™è¯¯: ç¦»çº¿æ¨¡å¼éœ€è¦æŒ‡å®š --input-file å‚æ•°")
        return
    
    # æ„å»ºé…ç½®
    config = {
        'mitm_host': args.mitm_host,
        'mitm_port': args.mitm_port,
        'output_dir': args.output_dir
    }
    
    # åˆ›å»ºå¹¶è¿è¡Œä¸»æµç¨‹
    pipeline = MainPipeline(config)
    result = pipeline.run_full_pipeline(
        offline_mode=args.offline,
        input_file=args.input_file
    )
    
    # è¾“å‡ºç»“æœ
    if result['success']:
        print(f"\nâœ… ä¸»æµç¨‹æ‰§è¡ŒæˆåŠŸ")
        if result.get('output_file'):
            print(f"ğŸ¯ æœ€ç»ˆè¾“å‡ºæ–‡ä»¶: {result['output_file']}")
    else:
        print(f"\nâŒ ä¸»æµç¨‹æ‰§è¡Œå¤±è´¥: {result['message']}")
        sys.exit(1)


if __name__ == "__main__":
    main()